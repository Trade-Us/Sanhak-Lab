{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f = open('resources/InsectWingbeatSound/InsectWingbeatSound_TEST','r')\n",
    "data = f.read()\n",
    "f.close()\n",
    "# 개행문자 기준으로 끊어서 리스트로\n",
    "data_list = data.split('\\n')\n",
    "\n",
    "# \",\" 기준으로 끊어서 리스트로\n",
    "emptylist = []\n",
    "for list_part in data_list:\n",
    "    emptylist.append(list_part.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str -> float 변환\n",
    "tofloat = []\n",
    "for partlist in emptylist:\n",
    "    tofloat.append([float(i) for i in partlist]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980,)\n",
      "(1980, 256)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "data_list = []\n",
    "for datas in tofloat:\n",
    "    labels.append(datas[0])\n",
    "    data_list.append(datas[1:])\n",
    "print(np.shape(labels))\n",
    "print(np.shape(data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readFile import split_into_values, toRPdata\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler\n",
    "\n",
    "def Standard(data):\n",
    "    SS = StandardScaler().fit(data)\n",
    "    scaled = SS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "def MinMax(data):\n",
    "    MMS = MinMaxScaler().fit(data)\n",
    "    scaled = MMS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "# result_list transpose\n",
    "result_T = [list(x) for x in zip(*data_list)]\n",
    "\n",
    "# minmax 정규화\n",
    "result_scaled = Standard(result_T)\n",
    "\n",
    "# 다시 result transpose 해서 원래대로\n",
    "result_scaled = [list(x) for x in zip(*result_scaled)]\n",
    "\n",
    "result_ = np.array(result_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256, 256, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = result_.reshape(result_.shape[0], 1, result_.shape[1])\n",
    "X = toRPdata(data, threshold='point', percentage=30)\n",
    "#X = toRPdata(data)\n",
    "    \n",
    "X_scaled = np.expand_dims(X, axis=3)\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11fa698f7b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-5\n",
    "optimizer='Adam'\n",
    "loss='mse'\n",
    "image_size = 256 #1024, 256\n",
    "dimension = 8 # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 128)     1280      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 2)         578       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 2)           38        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 2)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 32, 32, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        608       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 256, 1)       1153      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256, 256, 1)       0         \n",
      "=================================================================\n",
      "Total params: 188,265\n",
      "Trainable params: 188,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from utils import split_data, normalization_tool\n",
    "from agent import Autoencoder_Agent\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_data(X_scaled, X_scaled) #데이터 분리\n",
    "\n",
    "autoencoder = Autoencoder_Agent(model_size=image_size, dimension=dimension, optimizer=optimizer,learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6567\n",
      "Epoch 00001: val_loss improved from inf to 0.62312, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 26s 173ms/step - loss: 0.6567 - val_loss: 0.6231\n",
      "Epoch 2/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6120\n",
      "Epoch 00002: val_loss improved from 0.62312 to 0.60861, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.6120 - val_loss: 0.6086\n",
      "Epoch 3/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6066\n",
      "Epoch 00003: val_loss improved from 0.60861 to 0.60690, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.6066 - val_loss: 0.6069\n",
      "Epoch 4/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6046\n",
      "Epoch 00004: val_loss improved from 0.60690 to 0.60494, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.6046 - val_loss: 0.6049\n",
      "Epoch 5/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6022\n",
      "Epoch 00005: val_loss improved from 0.60494 to 0.60288, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.6022 - val_loss: 0.6029\n",
      "Epoch 6/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5981\n",
      "Epoch 00006: val_loss improved from 0.60288 to 0.59621, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5981 - val_loss: 0.5962\n",
      "Epoch 7/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5905\n",
      "Epoch 00007: val_loss improved from 0.59621 to 0.59202, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5905 - val_loss: 0.5920\n",
      "Epoch 8/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5853\n",
      "Epoch 00008: val_loss improved from 0.59202 to 0.58817, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5853 - val_loss: 0.5882\n",
      "Epoch 9/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5815\n",
      "Epoch 00009: val_loss improved from 0.58817 to 0.58622, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5815 - val_loss: 0.5862\n",
      "Epoch 10/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5791\n",
      "Epoch 00010: val_loss improved from 0.58622 to 0.58464, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5791 - val_loss: 0.5846\n",
      "Epoch 11/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5774\n",
      "Epoch 00011: val_loss improved from 0.58464 to 0.58332, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5774 - val_loss: 0.5833\n",
      "Epoch 12/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5761\n",
      "Epoch 00012: val_loss improved from 0.58332 to 0.58247, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5761 - val_loss: 0.5825\n",
      "Epoch 13/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5751\n",
      "Epoch 00013: val_loss improved from 0.58247 to 0.58152, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5751 - val_loss: 0.5815\n",
      "Epoch 14/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5743\n",
      "Epoch 00014: val_loss improved from 0.58152 to 0.58098, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5743 - val_loss: 0.5810\n",
      "Epoch 15/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5736\n",
      "Epoch 00015: val_loss improved from 0.58098 to 0.58062, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5736 - val_loss: 0.5806\n",
      "Epoch 16/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5732\n",
      "Epoch 00016: val_loss did not improve from 0.58062\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5732 - val_loss: 0.5808\n",
      "Epoch 17/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5727\n",
      "Epoch 00017: val_loss improved from 0.58062 to 0.58023, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5727 - val_loss: 0.5802\n",
      "Epoch 18/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5724\n",
      "Epoch 00018: val_loss improved from 0.58023 to 0.58021, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5724 - val_loss: 0.5802\n",
      "Epoch 19/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5720\n",
      "Epoch 00019: val_loss improved from 0.58021 to 0.58020, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5720 - val_loss: 0.5802\n",
      "Epoch 20/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5716\n",
      "Epoch 00020: val_loss improved from 0.58020 to 0.57979, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5716 - val_loss: 0.5798\n",
      "Epoch 21/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5714\n",
      "Epoch 00021: val_loss did not improve from 0.57979\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5714 - val_loss: 0.5799\n",
      "Epoch 22/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5712\n",
      "Epoch 00022: val_loss did not improve from 0.57979\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5712 - val_loss: 0.5800\n",
      "Epoch 23/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5708\n",
      "Epoch 00023: val_loss did not improve from 0.57979\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5708 - val_loss: 0.5802\n",
      "Epoch 24/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5707\n",
      "Epoch 00024: val_loss did not improve from 0.57979\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5707 - val_loss: 0.5799\n",
      "Epoch 25/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5704\n",
      "Epoch 00025: val_loss improved from 0.57979 to 0.57956, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5704 - val_loss: 0.5796\n",
      "Epoch 26/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5702\n",
      "Epoch 00026: val_loss did not improve from 0.57956\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5702 - val_loss: 0.5799\n",
      "Epoch 27/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5700\n",
      "Epoch 00027: val_loss improved from 0.57956 to 0.57936, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5700 - val_loss: 0.5794\n",
      "Epoch 28/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5699\n",
      "Epoch 00028: val_loss did not improve from 0.57936\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5699 - val_loss: 0.5796\n",
      "Epoch 29/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5696\n",
      "Epoch 00029: val_loss did not improve from 0.57936\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5696 - val_loss: 0.5796\n",
      "Epoch 30/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5694\n",
      "Epoch 00030: val_loss did not improve from 0.57936\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5694 - val_loss: 0.5794\n",
      "Epoch 31/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5693\n",
      "Epoch 00031: val_loss did not improve from 0.57936\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5693 - val_loss: 0.5795\n",
      "Epoch 32/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5690\n",
      "Epoch 00032: val_loss did not improve from 0.57936\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5690 - val_loss: 0.5794\n",
      "Epoch 33/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5689\n",
      "Epoch 00033: val_loss improved from 0.57936 to 0.57927, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5689 - val_loss: 0.5793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5687\n",
      "Epoch 00034: val_loss did not improve from 0.57927\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5687 - val_loss: 0.5795\n",
      "Epoch 35/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5685\n",
      "Epoch 00035: val_loss improved from 0.57927 to 0.57921, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5685 - val_loss: 0.5792\n",
      "Epoch 36/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5685\n",
      "Epoch 00036: val_loss improved from 0.57921 to 0.57901, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5685 - val_loss: 0.5790\n",
      "Epoch 37/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5682\n",
      "Epoch 00037: val_loss did not improve from 0.57901\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5682 - val_loss: 0.5800\n",
      "Epoch 38/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5683\n",
      "Epoch 00038: val_loss improved from 0.57901 to 0.57887, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5683 - val_loss: 0.5789\n",
      "Epoch 39/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5679\n",
      "Epoch 00039: val_loss did not improve from 0.57887\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5679 - val_loss: 0.5793\n",
      "Epoch 40/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5676\n",
      "Epoch 00040: val_loss did not improve from 0.57887\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5676 - val_loss: 0.5794\n",
      "Epoch 41/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5675\n",
      "Epoch 00041: val_loss did not improve from 0.57887\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5675 - val_loss: 0.5791\n",
      "Epoch 42/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5674\n",
      "Epoch 00042: val_loss did not improve from 0.57887\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5674 - val_loss: 0.5792\n",
      "Epoch 43/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5674\n",
      "Epoch 00043: val_loss did not improve from 0.57887\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5674 - val_loss: 0.5791\n",
      "Epoch 44/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5673\n",
      "Epoch 00044: val_loss improved from 0.57887 to 0.57885, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5673 - val_loss: 0.5788\n",
      "Epoch 45/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5673\n",
      "Epoch 00045: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5673 - val_loss: 0.5790\n",
      "Epoch 46/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5670\n",
      "Epoch 00046: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5670 - val_loss: 0.5791\n",
      "Epoch 47/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5669\n",
      "Epoch 00047: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5669 - val_loss: 0.5793\n",
      "Epoch 48/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5668\n",
      "Epoch 00048: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5668 - val_loss: 0.5794\n",
      "Epoch 49/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5667\n",
      "Epoch 00049: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5667 - val_loss: 0.5789\n",
      "Epoch 50/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5665\n",
      "Epoch 00050: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5665 - val_loss: 0.5793\n",
      "Epoch 51/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5665\n",
      "Epoch 00051: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5665 - val_loss: 0.5789\n",
      "Epoch 52/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5665\n",
      "Epoch 00052: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5665 - val_loss: 0.5792\n",
      "Epoch 53/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5663\n",
      "Epoch 00053: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5663 - val_loss: 0.5789\n",
      "Epoch 54/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5663\n",
      "Epoch 00054: val_loss did not improve from 0.57885\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5663 - val_loss: 0.5790\n",
      "Epoch 55/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5662\n",
      "Epoch 00055: val_loss improved from 0.57885 to 0.57879, saving model to insectWing_dimension_8.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5662 - val_loss: 0.5788\n",
      "Epoch 56/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5662\n",
      "Epoch 00056: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5662 - val_loss: 0.5794\n",
      "Epoch 57/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5660\n",
      "Epoch 00057: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5660 - val_loss: 0.5793\n",
      "Epoch 58/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5659\n",
      "Epoch 00058: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5659 - val_loss: 0.5789\n",
      "Epoch 59/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5658\n",
      "Epoch 00059: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5658 - val_loss: 0.5791\n",
      "Epoch 60/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5658\n",
      "Epoch 00060: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5658 - val_loss: 0.5792\n",
      "Epoch 61/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5657\n",
      "Epoch 00061: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5657 - val_loss: 0.5791\n",
      "Epoch 62/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5656\n",
      "Epoch 00062: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5656 - val_loss: 0.5792\n",
      "Epoch 63/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5656\n",
      "Epoch 00063: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5656 - val_loss: 0.5791\n",
      "Epoch 64/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5654\n",
      "Epoch 00064: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5654 - val_loss: 0.5791\n",
      "Epoch 65/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5654\n",
      "Epoch 00065: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5654 - val_loss: 0.5790\n",
      "Epoch 66/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5653\n",
      "Epoch 00066: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5653 - val_loss: 0.5790\n",
      "Epoch 67/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5653\n",
      "Epoch 00067: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5653 - val_loss: 0.5788\n",
      "Epoch 68/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5652\n",
      "Epoch 00068: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5652 - val_loss: 0.5790\n",
      "Epoch 69/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5651\n",
      "Epoch 00069: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5651 - val_loss: 0.5791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5651\n",
      "Epoch 00070: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5651 - val_loss: 0.5789\n",
      "Epoch 71/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5651\n",
      "Epoch 00071: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5651 - val_loss: 0.5791\n",
      "Epoch 72/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5649\n",
      "Epoch 00072: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5649 - val_loss: 0.5791\n",
      "Epoch 73/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5650\n",
      "Epoch 00073: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5650 - val_loss: 0.5792\n",
      "Epoch 74/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5649\n",
      "Epoch 00074: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5649 - val_loss: 0.5795\n",
      "Epoch 75/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5649\n",
      "Epoch 00075: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5649 - val_loss: 0.5795\n",
      "Epoch 76/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5648\n",
      "Epoch 00076: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5648 - val_loss: 0.5790\n",
      "Epoch 77/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5647\n",
      "Epoch 00077: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5647 - val_loss: 0.5789\n",
      "Epoch 78/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5646\n",
      "Epoch 00078: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5646 - val_loss: 0.5790\n",
      "Epoch 79/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5646\n",
      "Epoch 00079: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5646 - val_loss: 0.5790\n",
      "Epoch 80/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5645\n",
      "Epoch 00080: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5645 - val_loss: 0.5791\n",
      "Epoch 81/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5645\n",
      "Epoch 00081: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5645 - val_loss: 0.5794\n",
      "Epoch 82/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5645\n",
      "Epoch 00082: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5645 - val_loss: 0.5790\n",
      "Epoch 83/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5645\n",
      "Epoch 00083: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5645 - val_loss: 0.5792\n",
      "Epoch 84/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5644\n",
      "Epoch 00084: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5644 - val_loss: 0.5791\n",
      "Epoch 85/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5645\n",
      "Epoch 00085: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5645 - val_loss: 0.5788\n",
      "Epoch 86/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5642\n",
      "Epoch 00086: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5642 - val_loss: 0.5804\n",
      "Epoch 87/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5643\n",
      "Epoch 00087: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5643 - val_loss: 0.5790\n",
      "Epoch 88/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5643\n",
      "Epoch 00088: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5643 - val_loss: 0.5790\n",
      "Epoch 89/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5642\n",
      "Epoch 00089: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5642 - val_loss: 0.5794\n",
      "Epoch 90/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5644\n",
      "Epoch 00090: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5644 - val_loss: 0.5792\n",
      "Epoch 91/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5641\n",
      "Epoch 00091: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5641 - val_loss: 0.5797\n",
      "Epoch 92/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5641\n",
      "Epoch 00092: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5641 - val_loss: 0.5791\n",
      "Epoch 93/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5640\n",
      "Epoch 00093: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5640 - val_loss: 0.5791\n",
      "Epoch 94/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5640\n",
      "Epoch 00094: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5640 - val_loss: 0.5790\n",
      "Epoch 95/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5640\n",
      "Epoch 00095: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5640 - val_loss: 0.5799\n",
      "Epoch 96/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5639\n",
      "Epoch 00096: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5639 - val_loss: 0.5790\n",
      "Epoch 97/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5640\n",
      "Epoch 00097: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5640 - val_loss: 0.5790\n",
      "Epoch 98/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5638\n",
      "Epoch 00098: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5638 - val_loss: 0.5794\n",
      "Epoch 99/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5640\n",
      "Epoch 00099: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5640 - val_loss: 0.5791\n",
      "Epoch 100/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5638\n",
      "Epoch 00100: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5638 - val_loss: 0.5789\n",
      "Epoch 101/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5638\n",
      "Epoch 00101: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5638 - val_loss: 0.5790\n",
      "Epoch 102/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5638\n",
      "Epoch 00102: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5638 - val_loss: 0.5792\n",
      "Epoch 103/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5637\n",
      "Epoch 00103: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5637 - val_loss: 0.5791\n",
      "Epoch 104/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5637\n",
      "Epoch 00104: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5637 - val_loss: 0.5794\n",
      "Epoch 105/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5637\n",
      "Epoch 00105: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5637 - val_loss: 0.5791\n",
      "Epoch 106/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5637\n",
      "Epoch 00106: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5637 - val_loss: 0.5795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5637\n",
      "Epoch 00107: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5637 - val_loss: 0.5790\n",
      "Epoch 108/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5636\n",
      "Epoch 00108: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5636 - val_loss: 0.5794\n",
      "Epoch 109/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5636\n",
      "Epoch 00109: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5636 - val_loss: 0.5793\n",
      "Epoch 110/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5637\n",
      "Epoch 00110: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5637 - val_loss: 0.5791\n",
      "Epoch 111/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5635\n",
      "Epoch 00111: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5635 - val_loss: 0.5797\n",
      "Epoch 112/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5635\n",
      "Epoch 00112: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5635 - val_loss: 0.5791\n",
      "Epoch 113/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5635\n",
      "Epoch 00113: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5635 - val_loss: 0.5792\n",
      "Epoch 114/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5635\n",
      "Epoch 00114: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5635 - val_loss: 0.5793\n",
      "Epoch 115/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5634\n",
      "Epoch 00115: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5634 - val_loss: 0.5791\n",
      "Epoch 116/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5633\n",
      "Epoch 00116: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5633 - val_loss: 0.5791\n",
      "Epoch 117/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5633\n",
      "Epoch 00117: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5633 - val_loss: 0.5793\n",
      "Epoch 118/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5633\n",
      "Epoch 00118: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5633 - val_loss: 0.5796\n",
      "Epoch 119/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5634\n",
      "Epoch 00119: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5634 - val_loss: 0.5793\n",
      "Epoch 120/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5633\n",
      "Epoch 00120: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5633 - val_loss: 0.5792\n",
      "Epoch 121/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5632\n",
      "Epoch 00121: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5632 - val_loss: 0.5792\n",
      "Epoch 122/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5632\n",
      "Epoch 00122: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5632 - val_loss: 0.5795\n",
      "Epoch 123/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5632\n",
      "Epoch 00123: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5632 - val_loss: 0.5792\n",
      "Epoch 124/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5632\n",
      "Epoch 00124: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5632 - val_loss: 0.5795\n",
      "Epoch 125/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5633\n",
      "Epoch 00125: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5633 - val_loss: 0.5794\n",
      "Epoch 126/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5631\n",
      "Epoch 00126: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5631 - val_loss: 0.5792\n",
      "Epoch 127/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5632\n",
      "Epoch 00127: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5632 - val_loss: 0.5792\n",
      "Epoch 128/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5631\n",
      "Epoch 00128: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5631 - val_loss: 0.5796\n",
      "Epoch 129/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5631\n",
      "Epoch 00129: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5631 - val_loss: 0.5792\n",
      "Epoch 130/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5631\n",
      "Epoch 00130: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5631 - val_loss: 0.5791\n",
      "Epoch 131/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5630\n",
      "Epoch 00131: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5630 - val_loss: 0.5791\n",
      "Epoch 132/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5630\n",
      "Epoch 00132: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5630 - val_loss: 0.5790\n",
      "Epoch 133/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5630\n",
      "Epoch 00133: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5630 - val_loss: 0.5796\n",
      "Epoch 134/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5630\n",
      "Epoch 00134: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5630 - val_loss: 0.5794\n",
      "Epoch 135/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5630\n",
      "Epoch 00135: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5630 - val_loss: 0.5791\n",
      "Epoch 136/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5630\n",
      "Epoch 00136: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5630 - val_loss: 0.5797\n",
      "Epoch 137/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5629\n",
      "Epoch 00137: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5629 - val_loss: 0.5796\n",
      "Epoch 138/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5629\n",
      "Epoch 00138: val_loss did not improve from 0.57879\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5629 - val_loss: 0.5798\n",
      "Epoch 00138: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.train(X_train,batch_size,epochs,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "# loss_ax.plot([hist['loss'][i] - hist['val_loss'][i] for i in range(len(hist['loss']))], 'g', label='loss - val loss')\n",
    "\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 8)\n"
     ]
    }
   ],
   "source": [
    "features = np.empty((0,8), float)\n",
    "for i in range(66):\n",
    "    features = np.append(features, autoencoder.feature_extract(X_scaled[i*30:(i+1)*30]), axis=0)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1970727484177404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "result = KMeans(n_clusters=11).fit(features)\n",
    "plotSilhouette(features,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  2  0  8  4  7  8 10  2  7  1  9  1  8  8  0  8  7  5  2  8  4  1  2\n",
      "  8  8  0  7  8  8 10  8  7  8 10 10  5  8  8  8  2  7  5  0 10  8 10  7\n",
      " 10  0  0  8  1  5  4 10 10  8 10  4  1  4 10  1 10  6  3  0  5  8  1  9\n",
      " 10  7  0 10  6 10  8  2  0  9  8 10  0  7  8 10  4  7  4 10 10  7 10  4\n",
      "  4  8  4  5  8  7  1  9  7  7  8  4  0  7  4  8  6 10 10  4  7  5  9  8\n",
      "  8  1  5  4  9 10  2  2 10  0  9  4  9  7  5  8 10  8  7 10  5  8 10  2\n",
      "  4  2  8  3  4  0  8  7  7 10  5  4  5  8  8  0  8  8  1  0  8  8  9  2\n",
      "  5  2  1  1  1  7 10  8  4  1  5  4  7  7 10  0 10  5  0  7  6  4  4 10\n",
      "  5  0  8  7  4  4  8  3  8  2  7  1 10  9  8 10  4  7  1  4  8  7  7  4\n",
      "  1  8  7  0  4 10  5  1  0  4  9  9  4  2  2  9  8  9  4  4  0  4  7  2\n",
      "  7  0  1  3  3  4  4  2  8  0  4 10  0 10 10  0  9 10  4  0  7  8  8  1\n",
      "  0  2  4  9 10  8  3  2 10  1 10  8 10  2  4  8  4  8  8  8 10 10  0 10\n",
      "  5  9 10  4 10  4  7  4  8 10  8  8  0  0  5  7  0  3  7  7 10  8  8  7\n",
      "  0  7  0  7 10  4  8  0  8  8  8  0  5  2  7  2 10  8 10  9 10  2 10  0\n",
      "  1  4 10  7  8  0 10  7  2  4 10 10  8  4  0 10  9  4 10  9  7  7  8  4\n",
      "  7 10  9  8  4  1  0  4  4  0  7  7  7  8  1  4  0  4 10  7  8  6 10  4\n",
      " 10  1  0  0  5  0  8  4  8  8 10  5  7  4 10  7  7  0  0  8  8  4  8 10\n",
      " 10 10  5  0 10  8  2  4  5  5  9  0  4  7 10  7  8  4  2  9  4  1  8  2\n",
      "  8  4  7  4  4  0  9  8  2  0  1  8  2  1  8  3  8  4  7  7  8  8  0  7\n",
      "  0  0  2 10  8  4  1  0  7  4  1 10  7  8  0  4  2  8  7  9  8  0  4  4\n",
      "  8 10  2  8  2  0  8  2  7  0 10  3  7  2 10  9 10 10  0  5  7 10  4  0\n",
      "  7  5  5  8  4  7  5  0  8  7  8 10  7  9 10  8  2  4  1  2  7  4  8  4\n",
      "  8  8 10  7  0  8  0  7  8  9  4  8  7  9  0  8  5  7 10  4 10  7  7  8\n",
      "  0  8  8  5 10 10 10 10  9  8  8 10  4  5  1 10  7  8  0 10  0  7  5  4\n",
      "  0  0 10  8  8  8  2 10  1 10  7  1  4  2  8  7  1  8  4  0  7 10  0  2\n",
      "  2 10 10 10  5  4  4  4  4 10  7 10  9  4  8 10  8  4  8 10  8  0  8  8\n",
      "  7  7  4  7 10 10  0 10  8  8  0  0  0  5  0  4  8 10  4  7  4  8  8  2\n",
      "  4  2  7  4  1  8  5  7 10  9  0  0  8  9  2 10  2  1  7 10  4  5  7  1\n",
      "  4  8  7 10 10  4 10 10  1  8  0 10  4  8  3  5  0 10  4  9  7  6  4  4\n",
      "  7  8  2  0  8  1  9  4  8  7 10  9  7  8 10  3  8 10  8  0  0  7  7 10\n",
      "  3 10  7 10  8  8 10  8  4  9  8  5  4  8  8  7  8  4  4  2  7  0  5 10\n",
      "  8  8  0  8  4  0 10  7  1  8  8  7  1  9  9  1  0  8  7  1 10  4 10  1\n",
      " 10 10  7  8  0  4  3  7  2  3  1  8  4  2  8  4  7  6  2  4  2  9  8  4\n",
      "  6 10  7  7  5  7  4  9  1  7  0  5  7 10  9  0  0 10  7  2  8  0  8  9\n",
      "  0  8  8  8 10  7  7 10  8  2  4  4 10  2  0  8  0  1  7 10  8  0  8  7\n",
      "  8  9  7  2  9  3  7  8  4  4  8 10  4  0  7  2  2 10  7  0  7 10  4  8\n",
      "  8 10  0  2  4  0 10  7 10 10  0  7  6 10  9  0  2  1  0  2  9  8  4  4\n",
      " 10  7  6  0  9  9  5  4  8  8  2  0  0  5  0  8  7  4  8  8  8  0 10 10\n",
      "  7  8  7  8  0  4  8 10  1  2 10  8  1  8  0  1  4  3  8  5  0  8  9 10\n",
      "  9  8  4  8  1  2  1  7  8  2  9  1  0  3  0  8  1  4  7  8 10  5  4  1\n",
      "  1 10  0 10  8  0  8  2  2  7  7  8  4  9  2  1  8  7  8  8  7  0  0  9\n",
      "  1  9  8 10  7  4  7  1  7 10  7  5  0  0 10  0  5  2  3  0  0  9  4 10\n",
      "  0  0  1  7  1  2  5  4 10  4 10  8  1 10  8 10  9  1  8  8  0  4  8  8\n",
      " 10  4  4  9  8  8  8  8  2  8  8  8  9  2  2  8  8  8  0  4  1  5  8  2\n",
      "  0  0  2  7  9  8  0  5  9  4 10  8  9  7  9  7  8  4  4  7  4 10  2 10\n",
      "  9  0  4  5 10  5 10  2 10 10  7  4  9  8  3  4  6  7 10  9 10  0  8  0\n",
      "  1  2  4  8  8  7 10  0  0  8  8  8  7  7  0  4  4 10  4  8 10  0  4  2\n",
      "  0  2  4 10  7  7  1  9  7  8 10  8  8  1  9  3  0  4  7  8  9  7  9  9\n",
      "  6 10  9  8  4  8  9  1 10  7  1  4 10  7  4  6  6  4  0  2  4 10  8 10\n",
      "  7  1  4  7  2  0 10  1  2  7  0 10  7  2  7  7  7 10  7  4  5  7  1  8\n",
      "  5  8  7  1  4  4  8  8  7  1  1  7  8  0 10 10  2 10 10  3  8 10  7  8\n",
      "  3  7  1  8  5  7  1  8  7  1  1  8  8  8  1  8 10  1  4  7  7  8  7  9\n",
      "  2  8  9  2  9 10  8  9  4  7  9 10  8  5  1  7  8  0  0  2  8  7  1  4\n",
      "  8  1  2  3  8  8  0  4  8  7 10  0  8  9  8  8 10  8  8  8  8  4  7  1\n",
      "  8  2  9  5  8  9  5  5  8  9  7  8  1  7  2  9  7  4  2  5  8  0  4  4\n",
      " 10  4  4  1  8  7  8  7  1  2  1  4  8  2  1  8  0 10  1  8 10 10  0  0\n",
      " 10  4  2 10  4  0  5  4  2  1  0 10  8  4  5  9 10 10  4 10  0  8  1  8\n",
      "  0  7  7  8  7 10  8  0  3  9  5  3  2  0 10 10  8  8  2  0  4  7  4  9\n",
      "  4  1 10 10 10  7  0  9  4  7 10  8  0  4  2  1  5 10  8  7  7  8  7  8\n",
      "  2  8  4  4  8  9  0  9 10  2  8  7  2  8  4  1  8  9 10  8  8  8 10  8\n",
      "  7 10 10  7  0  4  7  7 10  0  4  7  1  9  7  4  7  5 10 10  0  2 10  0\n",
      "  0  0  4  7  5  0 10  5  8  2 10  8  4  4  9 10  4  8 10  6  4  7  1 10\n",
      " 10  8  0  2  0  9  4  1  5  8  1 10 10  9  8  7  8  2  2  0  9  0  9  8\n",
      "  9  8  1  9  8 10  0  4 10  8  2 10  4  0  7  1  0  1  0 10  3  2 10  2\n",
      "  7  0  7  4  7  8  4 10  0 10  1  4  4  8  7  4  4  8  7  5 10 10  8  0\n",
      "  7  3  8  7  8  6  7  8  1  8  0  9  9  7  4  1 10  0  2 10  8  1  8  0\n",
      "  4  8 10  3 10  9 10  1  8  5  0  0  8  6  7  7  2  0  9  2  7  0  7  2\n",
      "  0  3  7 10  1  1  5 10  1 10 10  8  4  7 10  0  8  8  2  7  7  9  7  7\n",
      "  0  2  8  1  1  0  8  4  8  7  8  4  2  8  0  7  0  9  7 10 10  4  7  4\n",
      "  8  4  0  0  2  4  1 10  8  2  7  1  1  8  0  2  8  5  0  7  2  7  8  4\n",
      "  8  5  4 10  9  8  8  4  8  8 10  0  1  2  4  7  8  8 10  2  7  8 10  4\n",
      "  2  8  6 10 10  0  8  9  2  4  1  4 10  4  7  8  9  1  1  0 10  0  7  8\n",
      "  1  5 10  7  8 10  0  8 10  7  4 10  7  7  1  8  7  2 10  7  2  4  4  7\n",
      "  8  0  2  9  8  7 10  4  4 10  1  8  1 10  5  8  1  5  2  7  4 10  1  0\n",
      "  1  7  0  9  9  4 10  8 10  8  7  5  2  9  4  2  4  8 10  0  8  9  9  8\n",
      "  0 10  7  0 10  9  0  7  8  9  2  7  6  4  8 10 10  7  8  4  2  7  4  2\n",
      "  4  1  3  0  4  8  3 10  2  2  7  8  7  2  7  8  8 10 10  5  0  9  7  7\n",
      "  0  4  8  7  8  0  1  4  4  9  7  4  0 10  8  0  8  8  7  0  2  8  4  7\n",
      "  2 10  0  0  4  4  0  9  8  5  7  4  1  8 10  4 10  0  5  8  2  8  8  7\n",
      "  7  8 10 10  0  2 10  8  7  7  8  4  0  4 10  4  5  6 10  8  7  8  7  8\n",
      "  7 10  5  8 10  4  8  7  4  7  8  4 10  8  9  8  4  0 10 10 10  7  0  8\n",
      "  9 10 10  0 10  2  8  8 10  2 10  8 10  8  0 10  4  4  0 10  9  4  6  4\n",
      "  5 10  2 10  4  7 10  2  1  5  5  0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "print(result.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score\n",
    "from matplotlib import cm\n",
    "\n",
    "def plotSilhouette(X, y_km):\n",
    "    cluster_labels = np.unique(y_km.labels_)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_score(X, y_km.labels_,metric='euclidean')\n",
    "    print(silhouette_vals)\n",
    "#     y_ax_lower, y_ax_upper = 0,0\n",
    "#     yticks = []\n",
    "    \n",
    "#     for i , c in enumerate(cluster_labels):\n",
    "#         c_silhouette_vals = silhouette_vals[y_km.labels_ == c]\n",
    "#         c_silhouette_vals.sort()\n",
    "#         y_ax_upper += len(c_silhouette_vals)\n",
    "#         color = cm.jet(i/n_clusters)\n",
    "        \n",
    "#         plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0,edgecolor='none', color=color)\n",
    "#         yticks.append((y_ax_lower + y_ax_upper)/2)\n",
    "#         y_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "#     silhouette_avg = np.mean(silhouette_vals)\n",
    "#     plt.axvline(silhouette_avg, color='red', linestyle='--')\n",
    "#     plt.yticks(yticks, cluster_labels+1)\n",
    "#     plt.ylabel('cluster')\n",
    "#     plt.xlabel('silhouette score')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2279039883123083\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"insect_128_8_bce.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
