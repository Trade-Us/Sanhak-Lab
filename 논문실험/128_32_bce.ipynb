{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f = open('resources/InsectWingbeatSound/InsectWingbeatSound_TEST','r')\n",
    "data = f.read()\n",
    "f.close()\n",
    "# 개행문자 기준으로 끊어서 리스트로\n",
    "data_list = data.split('\\n')\n",
    "\n",
    "# \",\" 기준으로 끊어서 리스트로\n",
    "emptylist = []\n",
    "for list_part in data_list:\n",
    "    emptylist.append(list_part.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str -> float 변환\n",
    "tofloat = []\n",
    "for partlist in emptylist:\n",
    "    tofloat.append([float(i) for i in partlist]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980,)\n",
      "(1980, 256)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "data_list = []\n",
    "for datas in tofloat:\n",
    "    labels.append(datas[0])\n",
    "    data_list.append(datas[1:])\n",
    "print(np.shape(labels))\n",
    "print(np.shape(data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readFile import split_into_values, toRPdata\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler\n",
    "\n",
    "def Standard(data):\n",
    "    SS = StandardScaler().fit(data)\n",
    "    scaled = SS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "def MinMax(data):\n",
    "    MMS = MinMaxScaler().fit(data)\n",
    "    scaled = MMS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "# result_list transpose\n",
    "result_T = [list(x) for x in zip(*data_list)]\n",
    "\n",
    "# minmax 정규화\n",
    "result_scaled = Standard(result_T)\n",
    "\n",
    "# 다시 result transpose 해서 원래대로\n",
    "result_scaled = [list(x) for x in zip(*result_scaled)]\n",
    "\n",
    "result_ = np.array(result_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256, 256, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = result_.reshape(result_.shape[0], 1, result_.shape[1])\n",
    "X = toRPdata(data, threshold='point', percentage=30)\n",
    "#X = toRPdata(data)\n",
    "    \n",
    "X_scaled = np.expand_dims(X, axis=3)\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2283e052cf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-5\n",
    "optimizer='Adam'\n",
    "loss='mse'\n",
    "image_size = 256 #1024, 256\n",
    "dimension = 32 # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 128)     1280      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 2)         578       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 2)           38        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 2)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 32, 32, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        608       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 256, 1)       1153      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256, 256, 1)       0         \n",
      "=================================================================\n",
      "Total params: 188,265\n",
      "Trainable params: 188,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from utils import split_data, normalization_tool\n",
    "from agent import Autoencoder_Agent\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_data(X_scaled, X_scaled) #데이터 분리\n",
    "\n",
    "autoencoder = Autoencoder_Agent(model_size=image_size, dimension=dimension, optimizer=optimizer,learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6691\n",
      "Epoch 00001: val_loss improved from inf to 0.64143, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 26s 172ms/step - loss: 0.6691 - val_loss: 0.6414\n",
      "Epoch 2/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6072\n",
      "Epoch 00002: val_loss improved from 0.64143 to 0.58934, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.6072 - val_loss: 0.5893\n",
      "Epoch 3/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5862\n",
      "Epoch 00003: val_loss improved from 0.58934 to 0.58575, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5862 - val_loss: 0.5857\n",
      "Epoch 4/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5831\n",
      "Epoch 00004: val_loss improved from 0.58575 to 0.58386, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5831 - val_loss: 0.5839\n",
      "Epoch 5/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5809\n",
      "Epoch 00005: val_loss improved from 0.58386 to 0.58185, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5809 - val_loss: 0.5819\n",
      "Epoch 6/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5793\n",
      "Epoch 00006: val_loss improved from 0.58185 to 0.58056, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5793 - val_loss: 0.5806\n",
      "Epoch 7/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5776\n",
      "Epoch 00007: val_loss improved from 0.58056 to 0.57848, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5776 - val_loss: 0.5785\n",
      "Epoch 8/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5763\n",
      "Epoch 00008: val_loss improved from 0.57848 to 0.57697, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5763 - val_loss: 0.5770\n",
      "Epoch 9/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5748\n",
      "Epoch 00009: val_loss improved from 0.57697 to 0.57637, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5748 - val_loss: 0.5764\n",
      "Epoch 10/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5736\n",
      "Epoch 00010: val_loss improved from 0.57637 to 0.57457, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5736 - val_loss: 0.5746\n",
      "Epoch 11/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5724\n",
      "Epoch 00011: val_loss improved from 0.57457 to 0.57338, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5724 - val_loss: 0.5734\n",
      "Epoch 12/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5716\n",
      "Epoch 00012: val_loss improved from 0.57338 to 0.57256, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5716 - val_loss: 0.5726\n",
      "Epoch 13/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5705\n",
      "Epoch 00013: val_loss improved from 0.57256 to 0.57150, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5705 - val_loss: 0.5715\n",
      "Epoch 14/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5696\n",
      "Epoch 00014: val_loss improved from 0.57150 to 0.57105, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5696 - val_loss: 0.5710\n",
      "Epoch 15/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5688\n",
      "Epoch 00015: val_loss improved from 0.57105 to 0.57010, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5688 - val_loss: 0.5701\n",
      "Epoch 16/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5680\n",
      "Epoch 00016: val_loss improved from 0.57010 to 0.57008, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5680 - val_loss: 0.5701\n",
      "Epoch 17/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5674\n",
      "Epoch 00017: val_loss improved from 0.57008 to 0.56934, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5674 - val_loss: 0.5693\n",
      "Epoch 18/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5667\n",
      "Epoch 00018: val_loss improved from 0.56934 to 0.56840, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5667 - val_loss: 0.5684\n",
      "Epoch 19/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5661\n",
      "Epoch 00019: val_loss improved from 0.56840 to 0.56761, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5661 - val_loss: 0.5676\n",
      "Epoch 20/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5654\n",
      "Epoch 00020: val_loss improved from 0.56761 to 0.56706, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5654 - val_loss: 0.5671\n",
      "Epoch 21/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5649\n",
      "Epoch 00021: val_loss improved from 0.56706 to 0.56675, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5649 - val_loss: 0.5667\n",
      "Epoch 22/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5644\n",
      "Epoch 00022: val_loss improved from 0.56675 to 0.56627, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5644 - val_loss: 0.5663\n",
      "Epoch 23/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5638\n",
      "Epoch 00023: val_loss improved from 0.56627 to 0.56595, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5638 - val_loss: 0.5660\n",
      "Epoch 24/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5633\n",
      "Epoch 00024: val_loss improved from 0.56595 to 0.56593, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5633 - val_loss: 0.5659\n",
      "Epoch 25/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5629\n",
      "Epoch 00025: val_loss improved from 0.56593 to 0.56544, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5629 - val_loss: 0.5654\n",
      "Epoch 26/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5623\n",
      "Epoch 00026: val_loss improved from 0.56544 to 0.56425, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5623 - val_loss: 0.5643\n",
      "Epoch 27/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5619\n",
      "Epoch 00027: val_loss improved from 0.56425 to 0.56401, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5619 - val_loss: 0.5640\n",
      "Epoch 28/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5615\n",
      "Epoch 00028: val_loss improved from 0.56401 to 0.56350, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5615 - val_loss: 0.5635\n",
      "Epoch 29/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5609\n",
      "Epoch 00029: val_loss improved from 0.56350 to 0.56331, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5609 - val_loss: 0.5633\n",
      "Epoch 30/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5608\n",
      "Epoch 00030: val_loss improved from 0.56331 to 0.56278, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5608 - val_loss: 0.5628\n",
      "Epoch 31/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5603\n",
      "Epoch 00031: val_loss improved from 0.56278 to 0.56242, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5603 - val_loss: 0.5624\n",
      "Epoch 32/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5597\n",
      "Epoch 00032: val_loss improved from 0.56242 to 0.56202, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5597 - val_loss: 0.5620\n",
      "Epoch 33/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5594\n",
      "Epoch 00033: val_loss improved from 0.56202 to 0.56168, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5594 - val_loss: 0.5617\n",
      "Epoch 34/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5589\n",
      "Epoch 00034: val_loss improved from 0.56168 to 0.56136, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5589 - val_loss: 0.5614\n",
      "Epoch 35/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5587\n",
      "Epoch 00035: val_loss improved from 0.56136 to 0.56107, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5587 - val_loss: 0.5611\n",
      "Epoch 36/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5584\n",
      "Epoch 00036: val_loss improved from 0.56107 to 0.56074, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5584 - val_loss: 0.5607\n",
      "Epoch 37/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5579\n",
      "Epoch 00037: val_loss improved from 0.56074 to 0.56052, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5579 - val_loss: 0.5605\n",
      "Epoch 38/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5577\n",
      "Epoch 00038: val_loss did not improve from 0.56052\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5577 - val_loss: 0.5606\n",
      "Epoch 39/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5573\n",
      "Epoch 00039: val_loss improved from 0.56052 to 0.55996, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5573 - val_loss: 0.5600\n",
      "Epoch 40/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5571\n",
      "Epoch 00040: val_loss did not improve from 0.55996\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5571 - val_loss: 0.5603\n",
      "Epoch 41/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5570\n",
      "Epoch 00041: val_loss improved from 0.55996 to 0.55939, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5570 - val_loss: 0.5594\n",
      "Epoch 42/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5565\n",
      "Epoch 00042: val_loss did not improve from 0.55939\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5565 - val_loss: 0.5595\n",
      "Epoch 43/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5563\n",
      "Epoch 00043: val_loss improved from 0.55939 to 0.55920, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5563 - val_loss: 0.5592\n",
      "Epoch 44/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5560\n",
      "Epoch 00044: val_loss improved from 0.55920 to 0.55897, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5560 - val_loss: 0.5590\n",
      "Epoch 45/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5558\n",
      "Epoch 00045: val_loss did not improve from 0.55897\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5558 - val_loss: 0.5592\n",
      "Epoch 46/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5555\n",
      "Epoch 00046: val_loss improved from 0.55897 to 0.55875, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5555 - val_loss: 0.5588\n",
      "Epoch 47/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5554\n",
      "Epoch 00047: val_loss did not improve from 0.55875\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5554 - val_loss: 0.5589\n",
      "Epoch 48/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5551\n",
      "Epoch 00048: val_loss improved from 0.55875 to 0.55806, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5551 - val_loss: 0.5581\n",
      "Epoch 49/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5549\n",
      "Epoch 00049: val_loss improved from 0.55806 to 0.55794, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5549 - val_loss: 0.5579\n",
      "Epoch 50/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5548\n",
      "Epoch 00050: val_loss did not improve from 0.55794\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5548 - val_loss: 0.5599\n",
      "Epoch 51/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5545\n",
      "Epoch 00051: val_loss improved from 0.55794 to 0.55787, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5545 - val_loss: 0.5579\n",
      "Epoch 52/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5543\n",
      "Epoch 00052: val_loss did not improve from 0.55787\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5543 - val_loss: 0.5582\n",
      "Epoch 53/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5541\n",
      "Epoch 00053: val_loss improved from 0.55787 to 0.55765, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 25s 164ms/step - loss: 0.5541 - val_loss: 0.5576\n",
      "Epoch 54/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5539\n",
      "Epoch 00054: val_loss did not improve from 0.55765\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5539 - val_loss: 0.5580\n",
      "Epoch 55/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5538\n",
      "Epoch 00055: val_loss improved from 0.55765 to 0.55717, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5538 - val_loss: 0.5572\n",
      "Epoch 56/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5536\n",
      "Epoch 00056: val_loss did not improve from 0.55717\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5536 - val_loss: 0.5572\n",
      "Epoch 57/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5534\n",
      "Epoch 00057: val_loss did not improve from 0.55717\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5534 - val_loss: 0.5575\n",
      "Epoch 58/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5533\n",
      "Epoch 00058: val_loss did not improve from 0.55717\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5533 - val_loss: 0.5574\n",
      "Epoch 59/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5532\n",
      "Epoch 00059: val_loss did not improve from 0.55717\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5532 - val_loss: 0.5579\n",
      "Epoch 60/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5529\n",
      "Epoch 00060: val_loss improved from 0.55717 to 0.55670, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5529 - val_loss: 0.5567\n",
      "Epoch 61/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5526\n",
      "Epoch 00061: val_loss improved from 0.55670 to 0.55659, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5526 - val_loss: 0.5566\n",
      "Epoch 62/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5524\n",
      "Epoch 00062: val_loss improved from 0.55659 to 0.55644, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5524 - val_loss: 0.5564\n",
      "Epoch 63/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5523\n",
      "Epoch 00063: val_loss improved from 0.55644 to 0.55615, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5523 - val_loss: 0.5562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5522\n",
      "Epoch 00064: val_loss improved from 0.55615 to 0.55603, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5522 - val_loss: 0.5560\n",
      "Epoch 65/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5520\n",
      "Epoch 00065: val_loss did not improve from 0.55603\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5520 - val_loss: 0.5570\n",
      "Epoch 66/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5519\n",
      "Epoch 00066: val_loss did not improve from 0.55603\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5519 - val_loss: 0.5579\n",
      "Epoch 67/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5519\n",
      "Epoch 00067: val_loss improved from 0.55603 to 0.55596, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5519 - val_loss: 0.5560\n",
      "Epoch 68/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5515\n",
      "Epoch 00068: val_loss improved from 0.55596 to 0.55566, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5515 - val_loss: 0.5557\n",
      "Epoch 69/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5514\n",
      "Epoch 00069: val_loss improved from 0.55566 to 0.55557, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5514 - val_loss: 0.5556\n",
      "Epoch 70/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5512\n",
      "Epoch 00070: val_loss improved from 0.55557 to 0.55538, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5512 - val_loss: 0.5554\n",
      "Epoch 71/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5511\n",
      "Epoch 00071: val_loss did not improve from 0.55538\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5511 - val_loss: 0.5554\n",
      "Epoch 72/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5510\n",
      "Epoch 00072: val_loss did not improve from 0.55538\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5510 - val_loss: 0.5557\n",
      "Epoch 73/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5509\n",
      "Epoch 00073: val_loss did not improve from 0.55538\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5509 - val_loss: 0.5555\n",
      "Epoch 74/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5507\n",
      "Epoch 00074: val_loss did not improve from 0.55538\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5507 - val_loss: 0.5555\n",
      "Epoch 75/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5506\n",
      "Epoch 00075: val_loss did not improve from 0.55538\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5506 - val_loss: 0.5558\n",
      "Epoch 76/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5506\n",
      "Epoch 00076: val_loss improved from 0.55538 to 0.55503, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5506 - val_loss: 0.5550\n",
      "Epoch 77/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5501\n",
      "Epoch 00077: val_loss improved from 0.55503 to 0.55496, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5501 - val_loss: 0.5550\n",
      "Epoch 78/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5500\n",
      "Epoch 00078: val_loss did not improve from 0.55496\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5500 - val_loss: 0.5551\n",
      "Epoch 79/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5502\n",
      "Epoch 00079: val_loss did not improve from 0.55496\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5502 - val_loss: 0.5558\n",
      "Epoch 80/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5499\n",
      "Epoch 00080: val_loss did not improve from 0.55496\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5499 - val_loss: 0.5552\n",
      "Epoch 81/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5496\n",
      "Epoch 00081: val_loss improved from 0.55496 to 0.55470, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5496 - val_loss: 0.5547\n",
      "Epoch 82/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5496\n",
      "Epoch 00082: val_loss improved from 0.55470 to 0.55462, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5496 - val_loss: 0.5546\n",
      "Epoch 83/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5495\n",
      "Epoch 00083: val_loss improved from 0.55462 to 0.55454, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5495 - val_loss: 0.5545\n",
      "Epoch 84/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5493\n",
      "Epoch 00084: val_loss improved from 0.55454 to 0.55444, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5493 - val_loss: 0.5544\n",
      "Epoch 85/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5492\n",
      "Epoch 00085: val_loss improved from 0.55444 to 0.55423, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5492 - val_loss: 0.5542\n",
      "Epoch 86/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5491\n",
      "Epoch 00086: val_loss improved from 0.55423 to 0.55418, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5491 - val_loss: 0.5542\n",
      "Epoch 87/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5490\n",
      "Epoch 00087: val_loss did not improve from 0.55418\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5490 - val_loss: 0.5542\n",
      "Epoch 88/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5487\n",
      "Epoch 00088: val_loss did not improve from 0.55418\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5487 - val_loss: 0.5545\n",
      "Epoch 89/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5487\n",
      "Epoch 00089: val_loss did not improve from 0.55418\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5487 - val_loss: 0.5543\n",
      "Epoch 90/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5485\n",
      "Epoch 00090: val_loss improved from 0.55418 to 0.55403, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5485 - val_loss: 0.5540\n",
      "Epoch 91/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5485\n",
      "Epoch 00091: val_loss did not improve from 0.55403\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5485 - val_loss: 0.5543\n",
      "Epoch 92/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5481\n",
      "Epoch 00092: val_loss improved from 0.55403 to 0.55390, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5481 - val_loss: 0.5539\n",
      "Epoch 93/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5482\n",
      "Epoch 00093: val_loss did not improve from 0.55390\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5482 - val_loss: 0.5544\n",
      "Epoch 94/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5481\n",
      "Epoch 00094: val_loss did not improve from 0.55390\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5481 - val_loss: 0.5546\n",
      "Epoch 95/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5478\n",
      "Epoch 00095: val_loss did not improve from 0.55390\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5478 - val_loss: 0.5546\n",
      "Epoch 96/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5478\n",
      "Epoch 00096: val_loss did not improve from 0.55390\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5478 - val_loss: 0.5542\n",
      "Epoch 97/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5475\n",
      "Epoch 00097: val_loss did not improve from 0.55390\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5475 - val_loss: 0.5542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5473\n",
      "Epoch 00098: val_loss improved from 0.55390 to 0.55363, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5473 - val_loss: 0.5536\n",
      "Epoch 99/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5472\n",
      "Epoch 00099: val_loss did not improve from 0.55363\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5472 - val_loss: 0.5540\n",
      "Epoch 100/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5472\n",
      "Epoch 00100: val_loss did not improve from 0.55363\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5472 - val_loss: 0.5546\n",
      "Epoch 101/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5469\n",
      "Epoch 00101: val_loss improved from 0.55363 to 0.55352, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5469 - val_loss: 0.5535\n",
      "Epoch 102/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5473\n",
      "Epoch 00102: val_loss did not improve from 0.55352\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5473 - val_loss: 0.5536\n",
      "Epoch 103/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5467\n",
      "Epoch 00103: val_loss did not improve from 0.55352\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5467 - val_loss: 0.5542\n",
      "Epoch 104/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5470\n",
      "Epoch 00104: val_loss did not improve from 0.55352\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5470 - val_loss: 0.5537\n",
      "Epoch 105/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5467\n",
      "Epoch 00105: val_loss improved from 0.55352 to 0.55347, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5467 - val_loss: 0.5535\n",
      "Epoch 106/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5466\n",
      "Epoch 00106: val_loss improved from 0.55347 to 0.55337, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5466 - val_loss: 0.5534\n",
      "Epoch 107/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5463\n",
      "Epoch 00107: val_loss improved from 0.55337 to 0.55301, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5463 - val_loss: 0.5530\n",
      "Epoch 108/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5462\n",
      "Epoch 00108: val_loss improved from 0.55301 to 0.55292, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5462 - val_loss: 0.5529\n",
      "Epoch 109/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5462\n",
      "Epoch 00109: val_loss did not improve from 0.55292\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5462 - val_loss: 0.5537\n",
      "Epoch 110/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5461\n",
      "Epoch 00110: val_loss did not improve from 0.55292\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5461 - val_loss: 0.5534\n",
      "Epoch 111/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5459\n",
      "Epoch 00111: val_loss did not improve from 0.55292\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5459 - val_loss: 0.5532\n",
      "Epoch 112/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5460\n",
      "Epoch 00112: val_loss did not improve from 0.55292\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5460 - val_loss: 0.5531\n",
      "Epoch 113/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5456\n",
      "Epoch 00113: val_loss did not improve from 0.55292\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5456 - val_loss: 0.5530\n",
      "Epoch 114/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5457\n",
      "Epoch 00114: val_loss did not improve from 0.55292\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5457 - val_loss: 0.5542\n",
      "Epoch 115/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5455\n",
      "Epoch 00115: val_loss did not improve from 0.55292\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5455 - val_loss: 0.5531\n",
      "Epoch 116/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5455\n",
      "Epoch 00116: val_loss did not improve from 0.55292\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5455 - val_loss: 0.5533\n",
      "Epoch 117/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5452\n",
      "Epoch 00117: val_loss improved from 0.55292 to 0.55275, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5452 - val_loss: 0.5527\n",
      "Epoch 118/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5451\n",
      "Epoch 00118: val_loss did not improve from 0.55275\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5451 - val_loss: 0.5532\n",
      "Epoch 119/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5450\n",
      "Epoch 00119: val_loss did not improve from 0.55275\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5450 - val_loss: 0.5529\n",
      "Epoch 120/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5448\n",
      "Epoch 00120: val_loss did not improve from 0.55275\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5448 - val_loss: 0.5528\n",
      "Epoch 121/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5451\n",
      "Epoch 00121: val_loss did not improve from 0.55275\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5451 - val_loss: 0.5530\n",
      "Epoch 122/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5447\n",
      "Epoch 00122: val_loss did not improve from 0.55275\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5447 - val_loss: 0.5528\n",
      "Epoch 123/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5449\n",
      "Epoch 00123: val_loss did not improve from 0.55275\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5449 - val_loss: 0.5529\n",
      "Epoch 124/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5444\n",
      "Epoch 00124: val_loss improved from 0.55275 to 0.55244, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5444 - val_loss: 0.5524\n",
      "Epoch 125/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5446\n",
      "Epoch 00125: val_loss did not improve from 0.55244\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5446 - val_loss: 0.5535\n",
      "Epoch 126/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5443\n",
      "Epoch 00126: val_loss did not improve from 0.55244\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5443 - val_loss: 0.5535\n",
      "Epoch 127/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5445\n",
      "Epoch 00127: val_loss improved from 0.55244 to 0.55240, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5445 - val_loss: 0.5524\n",
      "Epoch 128/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5441\n",
      "Epoch 00128: val_loss did not improve from 0.55240\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5441 - val_loss: 0.5530\n",
      "Epoch 129/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5442\n",
      "Epoch 00129: val_loss did not improve from 0.55240\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5442 - val_loss: 0.5525\n",
      "Epoch 130/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5440\n",
      "Epoch 00130: val_loss did not improve from 0.55240\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5440 - val_loss: 0.5526\n",
      "Epoch 131/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5439\n",
      "Epoch 00131: val_loss did not improve from 0.55240\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5439 - val_loss: 0.5527\n",
      "Epoch 132/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5440\n",
      "Epoch 00132: val_loss improved from 0.55240 to 0.55214, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5440 - val_loss: 0.5521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5435\n",
      "Epoch 00133: val_loss did not improve from 0.55214\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5435 - val_loss: 0.5536\n",
      "Epoch 134/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5435\n",
      "Epoch 00134: val_loss improved from 0.55214 to 0.55203, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5435 - val_loss: 0.5520\n",
      "Epoch 135/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5435\n",
      "Epoch 00135: val_loss did not improve from 0.55203\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5435 - val_loss: 0.5523\n",
      "Epoch 136/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5433\n",
      "Epoch 00136: val_loss improved from 0.55203 to 0.55186, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5433 - val_loss: 0.5519\n",
      "Epoch 137/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5432\n",
      "Epoch 00137: val_loss did not improve from 0.55186\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5432 - val_loss: 0.5528\n",
      "Epoch 138/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5433\n",
      "Epoch 00138: val_loss did not improve from 0.55186\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5433 - val_loss: 0.5526\n",
      "Epoch 139/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5430\n",
      "Epoch 00139: val_loss did not improve from 0.55186\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5430 - val_loss: 0.5522\n",
      "Epoch 140/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5429\n",
      "Epoch 00140: val_loss did not improve from 0.55186\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5429 - val_loss: 0.5520\n",
      "Epoch 141/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5429\n",
      "Epoch 00141: val_loss did not improve from 0.55186\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5429 - val_loss: 0.5533\n",
      "Epoch 142/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5428\n",
      "Epoch 00142: val_loss did not improve from 0.55186\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5428 - val_loss: 0.5522\n",
      "Epoch 143/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5427\n",
      "Epoch 00143: val_loss did not improve from 0.55186\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5427 - val_loss: 0.5526\n",
      "Epoch 144/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5424\n",
      "Epoch 00144: val_loss improved from 0.55186 to 0.55182, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5424 - val_loss: 0.5518\n",
      "Epoch 145/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5426\n",
      "Epoch 00145: val_loss did not improve from 0.55182\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5426 - val_loss: 0.5518\n",
      "Epoch 146/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5422\n",
      "Epoch 00146: val_loss did not improve from 0.55182\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5422 - val_loss: 0.5528\n",
      "Epoch 147/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5424\n",
      "Epoch 00147: val_loss did not improve from 0.55182\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5424 - val_loss: 0.5520\n",
      "Epoch 148/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5422\n",
      "Epoch 00148: val_loss improved from 0.55182 to 0.55166, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5422 - val_loss: 0.5517\n",
      "Epoch 149/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5421\n",
      "Epoch 00149: val_loss did not improve from 0.55166\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5421 - val_loss: 0.5518\n",
      "Epoch 150/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5420\n",
      "Epoch 00150: val_loss did not improve from 0.55166\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5420 - val_loss: 0.5526\n",
      "Epoch 151/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5419\n",
      "Epoch 00151: val_loss did not improve from 0.55166\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5419 - val_loss: 0.5533\n",
      "Epoch 152/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5417\n",
      "Epoch 00152: val_loss did not improve from 0.55166\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5417 - val_loss: 0.5521\n",
      "Epoch 153/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5417\n",
      "Epoch 00153: val_loss did not improve from 0.55166\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5417 - val_loss: 0.5517\n",
      "Epoch 154/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5416\n",
      "Epoch 00154: val_loss did not improve from 0.55166\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5416 - val_loss: 0.5535\n",
      "Epoch 155/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5414\n",
      "Epoch 00155: val_loss did not improve from 0.55166\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5414 - val_loss: 0.5518\n",
      "Epoch 156/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5414\n",
      "Epoch 00156: val_loss improved from 0.55166 to 0.55165, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5414 - val_loss: 0.5516\n",
      "Epoch 157/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5412\n",
      "Epoch 00157: val_loss did not improve from 0.55165\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5412 - val_loss: 0.5518\n",
      "Epoch 158/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5411\n",
      "Epoch 00158: val_loss did not improve from 0.55165\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5411 - val_loss: 0.5539\n",
      "Epoch 159/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5412\n",
      "Epoch 00159: val_loss did not improve from 0.55165\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5412 - val_loss: 0.5517\n",
      "Epoch 160/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5410\n",
      "Epoch 00160: val_loss did not improve from 0.55165\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5410 - val_loss: 0.5520\n",
      "Epoch 161/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5411\n",
      "Epoch 00161: val_loss improved from 0.55165 to 0.55157, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5411 - val_loss: 0.5516\n",
      "Epoch 162/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5407\n",
      "Epoch 00162: val_loss improved from 0.55157 to 0.55154, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5407 - val_loss: 0.5515\n",
      "Epoch 163/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5406\n",
      "Epoch 00163: val_loss did not improve from 0.55154\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5406 - val_loss: 0.5519\n",
      "Epoch 164/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5408\n",
      "Epoch 00164: val_loss did not improve from 0.55154\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5408 - val_loss: 0.5517\n",
      "Epoch 165/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5406\n",
      "Epoch 00165: val_loss did not improve from 0.55154\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5406 - val_loss: 0.5516\n",
      "Epoch 166/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5403\n",
      "Epoch 00166: val_loss did not improve from 0.55154\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5403 - val_loss: 0.5516\n",
      "Epoch 167/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5403\n",
      "Epoch 00167: val_loss did not improve from 0.55154\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5403 - val_loss: 0.5518\n",
      "Epoch 168/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5404\n",
      "Epoch 00168: val_loss improved from 0.55154 to 0.55140, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5404 - val_loss: 0.5514\n",
      "Epoch 169/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5402\n",
      "Epoch 00169: val_loss did not improve from 0.55140\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5402 - val_loss: 0.5517\n",
      "Epoch 170/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5400\n",
      "Epoch 00170: val_loss did not improve from 0.55140\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5400 - val_loss: 0.5524\n",
      "Epoch 171/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5400\n",
      "Epoch 00171: val_loss did not improve from 0.55140\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5400 - val_loss: 0.5514\n",
      "Epoch 172/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5398\n",
      "Epoch 00172: val_loss did not improve from 0.55140\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5398 - val_loss: 0.5522\n",
      "Epoch 173/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5397\n",
      "Epoch 00173: val_loss did not improve from 0.55140\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5397 - val_loss: 0.5517\n",
      "Epoch 174/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5397\n",
      "Epoch 00174: val_loss improved from 0.55140 to 0.55135, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5397 - val_loss: 0.5514\n",
      "Epoch 175/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5400\n",
      "Epoch 00175: val_loss did not improve from 0.55135\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5400 - val_loss: 0.5514\n",
      "Epoch 176/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5395\n",
      "Epoch 00176: val_loss did not improve from 0.55135\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5395 - val_loss: 0.5515\n",
      "Epoch 177/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5396\n",
      "Epoch 00177: val_loss did not improve from 0.55135\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5396 - val_loss: 0.5514\n",
      "Epoch 178/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5393\n",
      "Epoch 00178: val_loss did not improve from 0.55135\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5393 - val_loss: 0.5516\n",
      "Epoch 179/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5394\n",
      "Epoch 00179: val_loss did not improve from 0.55135\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5394 - val_loss: 0.5517\n",
      "Epoch 180/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5391\n",
      "Epoch 00180: val_loss did not improve from 0.55135\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5391 - val_loss: 0.5524\n",
      "Epoch 181/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5393\n",
      "Epoch 00181: val_loss improved from 0.55135 to 0.55116, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5393 - val_loss: 0.5512\n",
      "Epoch 182/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5391\n",
      "Epoch 00182: val_loss did not improve from 0.55116\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5391 - val_loss: 0.5516\n",
      "Epoch 183/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5389\n",
      "Epoch 00183: val_loss did not improve from 0.55116\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5389 - val_loss: 0.5516\n",
      "Epoch 184/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5388\n",
      "Epoch 00184: val_loss did not improve from 0.55116\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5388 - val_loss: 0.5517\n",
      "Epoch 185/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5389\n",
      "Epoch 00185: val_loss did not improve from 0.55116\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5389 - val_loss: 0.5521\n",
      "Epoch 186/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5388\n",
      "Epoch 00186: val_loss did not improve from 0.55116\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5388 - val_loss: 0.5520\n",
      "Epoch 187/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5385\n",
      "Epoch 00187: val_loss did not improve from 0.55116\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5385 - val_loss: 0.5517\n",
      "Epoch 188/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5385\n",
      "Epoch 00188: val_loss did not improve from 0.55116\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5385 - val_loss: 0.5516\n",
      "Epoch 189/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5385\n",
      "Epoch 00189: val_loss did not improve from 0.55116\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5385 - val_loss: 0.5525\n",
      "Epoch 190/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5384\n",
      "Epoch 00190: val_loss improved from 0.55116 to 0.55097, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5384 - val_loss: 0.5510\n",
      "Epoch 191/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5384\n",
      "Epoch 00191: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5384 - val_loss: 0.5514\n",
      "Epoch 192/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5380\n",
      "Epoch 00192: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5380 - val_loss: 0.5514\n",
      "Epoch 193/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5380\n",
      "Epoch 00193: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5380 - val_loss: 0.5515\n",
      "Epoch 194/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5379\n",
      "Epoch 00194: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5379 - val_loss: 0.5511\n",
      "Epoch 195/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5379\n",
      "Epoch 00195: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5379 - val_loss: 0.5512\n",
      "Epoch 196/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5377\n",
      "Epoch 00196: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5377 - val_loss: 0.5511\n",
      "Epoch 197/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5379\n",
      "Epoch 00197: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5379 - val_loss: 0.5524\n",
      "Epoch 198/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5378\n",
      "Epoch 00198: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5378 - val_loss: 0.5514\n",
      "Epoch 199/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5377\n",
      "Epoch 00199: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5377 - val_loss: 0.5512\n",
      "Epoch 200/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5376\n",
      "Epoch 00200: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5376 - val_loss: 0.5520\n",
      "Epoch 201/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5374\n",
      "Epoch 00201: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5374 - val_loss: 0.5516\n",
      "Epoch 202/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5376\n",
      "Epoch 00202: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5376 - val_loss: 0.5512\n",
      "Epoch 203/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5374\n",
      "Epoch 00203: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5374 - val_loss: 0.5510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5372\n",
      "Epoch 00204: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5372 - val_loss: 0.5514\n",
      "Epoch 205/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5375\n",
      "Epoch 00205: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5375 - val_loss: 0.5526\n",
      "Epoch 206/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5371\n",
      "Epoch 00206: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5371 - val_loss: 0.5512\n",
      "Epoch 207/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5369\n",
      "Epoch 00207: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5369 - val_loss: 0.5510\n",
      "Epoch 208/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5368\n",
      "Epoch 00208: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5368 - val_loss: 0.5518\n",
      "Epoch 209/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5368\n",
      "Epoch 00209: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5368 - val_loss: 0.5512\n",
      "Epoch 210/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5367\n",
      "Epoch 00210: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5367 - val_loss: 0.5512\n",
      "Epoch 211/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5366\n",
      "Epoch 00211: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5366 - val_loss: 0.5517\n",
      "Epoch 212/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5365\n",
      "Epoch 00212: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5365 - val_loss: 0.5519\n",
      "Epoch 213/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5365\n",
      "Epoch 00213: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5365 - val_loss: 0.5522\n",
      "Epoch 214/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5363\n",
      "Epoch 00214: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 25s 167ms/step - loss: 0.5363 - val_loss: 0.5514\n",
      "Epoch 215/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5364\n",
      "Epoch 00215: val_loss did not improve from 0.55097\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5364 - val_loss: 0.5515\n",
      "Epoch 216/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5362\n",
      "Epoch 00216: val_loss improved from 0.55097 to 0.55095, saving model to insectWing_dimension_32.h5\n",
      "149/149 [==============================] - 25s 168ms/step - loss: 0.5362 - val_loss: 0.5510\n",
      "Epoch 217/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5363\n",
      "Epoch 00217: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 169ms/step - loss: 0.5363 - val_loss: 0.5513\n",
      "Epoch 218/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5361\n",
      "Epoch 00218: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 167ms/step - loss: 0.5361 - val_loss: 0.5515\n",
      "Epoch 219/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5360\n",
      "Epoch 00219: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5360 - val_loss: 0.5514\n",
      "Epoch 220/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5360\n",
      "Epoch 00220: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5360 - val_loss: 0.5513\n",
      "Epoch 221/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5364\n",
      "Epoch 00221: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5364 - val_loss: 0.5517\n",
      "Epoch 222/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5357\n",
      "Epoch 00222: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5357 - val_loss: 0.5518\n",
      "Epoch 223/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5360\n",
      "Epoch 00223: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5360 - val_loss: 0.5515\n",
      "Epoch 224/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5356\n",
      "Epoch 00224: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5356 - val_loss: 0.5514\n",
      "Epoch 225/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5355\n",
      "Epoch 00225: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5355 - val_loss: 0.5517\n",
      "Epoch 226/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5356\n",
      "Epoch 00226: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5356 - val_loss: 0.5517\n",
      "Epoch 227/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5353\n",
      "Epoch 00227: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5353 - val_loss: 0.5515\n",
      "Epoch 228/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5355\n",
      "Epoch 00228: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5355 - val_loss: 0.5518\n",
      "Epoch 229/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5357\n",
      "Epoch 00229: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5357 - val_loss: 0.5511\n",
      "Epoch 230/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5351\n",
      "Epoch 00230: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5351 - val_loss: 0.5516\n",
      "Epoch 231/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5353\n",
      "Epoch 00231: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5353 - val_loss: 0.5518\n",
      "Epoch 232/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5350\n",
      "Epoch 00232: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5350 - val_loss: 0.5516\n",
      "Epoch 233/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5351\n",
      "Epoch 00233: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5351 - val_loss: 0.5514\n",
      "Epoch 234/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5348\n",
      "Epoch 00234: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5348 - val_loss: 0.5514\n",
      "Epoch 235/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5348\n",
      "Epoch 00235: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5348 - val_loss: 0.5523\n",
      "Epoch 236/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5349\n",
      "Epoch 00236: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5349 - val_loss: 0.5525\n",
      "Epoch 237/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5350\n",
      "Epoch 00237: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5350 - val_loss: 0.5514\n",
      "Epoch 238/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5346\n",
      "Epoch 00238: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5346 - val_loss: 0.5515\n",
      "Epoch 239/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5346\n",
      "Epoch 00239: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5346 - val_loss: 0.5513\n",
      "Epoch 240/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5347\n",
      "Epoch 00240: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5347 - val_loss: 0.5513\n",
      "Epoch 241/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5345\n",
      "Epoch 00241: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5345 - val_loss: 0.5515\n",
      "Epoch 242/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5344\n",
      "Epoch 00242: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5344 - val_loss: 0.5537\n",
      "Epoch 243/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5342\n",
      "Epoch 00243: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5342 - val_loss: 0.5525\n",
      "Epoch 244/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5343\n",
      "Epoch 00244: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5343 - val_loss: 0.5515\n",
      "Epoch 245/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5343\n",
      "Epoch 00245: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5343 - val_loss: 0.5516\n",
      "Epoch 246/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5340\n",
      "Epoch 00246: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5340 - val_loss: 0.5519\n",
      "Epoch 247/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5338\n",
      "Epoch 00247: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5338 - val_loss: 0.5520\n",
      "Epoch 248/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5340\n",
      "Epoch 00248: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5340 - val_loss: 0.5515\n",
      "Epoch 249/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5339\n",
      "Epoch 00249: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5339 - val_loss: 0.5512\n",
      "Epoch 250/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5337\n",
      "Epoch 00250: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5337 - val_loss: 0.5517\n",
      "Epoch 251/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5336\n",
      "Epoch 00251: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5336 - val_loss: 0.5519\n",
      "Epoch 252/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5336\n",
      "Epoch 00252: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5336 - val_loss: 0.5528\n",
      "Epoch 253/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5336\n",
      "Epoch 00253: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5336 - val_loss: 0.5523\n",
      "Epoch 254/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5338\n",
      "Epoch 00254: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5338 - val_loss: 0.5561\n",
      "Epoch 255/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5340\n",
      "Epoch 00255: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5340 - val_loss: 0.5526\n",
      "Epoch 256/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5335\n",
      "Epoch 00256: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5335 - val_loss: 0.5526\n",
      "Epoch 257/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5333\n",
      "Epoch 00257: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5333 - val_loss: 0.5529\n",
      "Epoch 258/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5333\n",
      "Epoch 00258: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5333 - val_loss: 0.5518\n",
      "Epoch 259/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5334\n",
      "Epoch 00259: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5334 - val_loss: 0.5516\n",
      "Epoch 260/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5330\n",
      "Epoch 00260: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5330 - val_loss: 0.5518\n",
      "Epoch 261/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5330\n",
      "Epoch 00261: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5330 - val_loss: 0.5530\n",
      "Epoch 262/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5331\n",
      "Epoch 00262: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5331 - val_loss: 0.5519\n",
      "Epoch 263/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5328\n",
      "Epoch 00263: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5328 - val_loss: 0.5516\n",
      "Epoch 264/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5327\n",
      "Epoch 00264: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5327 - val_loss: 0.5519\n",
      "Epoch 265/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5327\n",
      "Epoch 00265: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5327 - val_loss: 0.5517\n",
      "Epoch 266/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5326\n",
      "Epoch 00266: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 168ms/step - loss: 0.5326 - val_loss: 0.5518\n",
      "Epoch 267/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5326\n",
      "Epoch 00267: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 167ms/step - loss: 0.5326 - val_loss: 0.5518\n",
      "Epoch 268/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5327\n",
      "Epoch 00268: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5327 - val_loss: 0.5521\n",
      "Epoch 269/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5326\n",
      "Epoch 00269: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5326 - val_loss: 0.5519\n",
      "Epoch 270/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5325\n",
      "Epoch 00270: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5325 - val_loss: 0.5522\n",
      "Epoch 271/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5323\n",
      "Epoch 00271: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5323 - val_loss: 0.5523\n",
      "Epoch 272/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5325\n",
      "Epoch 00272: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5325 - val_loss: 0.5524\n",
      "Epoch 273/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5323\n",
      "Epoch 00273: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5323 - val_loss: 0.5516\n",
      "Epoch 274/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5321\n",
      "Epoch 00274: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5321 - val_loss: 0.5521\n",
      "Epoch 275/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5322\n",
      "Epoch 00275: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5322 - val_loss: 0.5521\n",
      "Epoch 276/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5320\n",
      "Epoch 00276: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5320 - val_loss: 0.5521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5319\n",
      "Epoch 00277: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5319 - val_loss: 0.5525\n",
      "Epoch 278/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5318\n",
      "Epoch 00278: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5318 - val_loss: 0.5523\n",
      "Epoch 279/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5319\n",
      "Epoch 00279: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5319 - val_loss: 0.5519\n",
      "Epoch 280/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5319\n",
      "Epoch 00280: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5319 - val_loss: 0.5525\n",
      "Epoch 281/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5317\n",
      "Epoch 00281: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5317 - val_loss: 0.5527\n",
      "Epoch 282/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5316\n",
      "Epoch 00282: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5316 - val_loss: 0.5522\n",
      "Epoch 283/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5317\n",
      "Epoch 00283: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5317 - val_loss: 0.5530\n",
      "Epoch 284/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5314\n",
      "Epoch 00284: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5314 - val_loss: 0.5519\n",
      "Epoch 285/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5314\n",
      "Epoch 00285: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5314 - val_loss: 0.5523\n",
      "Epoch 286/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5314\n",
      "Epoch 00286: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5314 - val_loss: 0.5524\n",
      "Epoch 287/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5313\n",
      "Epoch 00287: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5313 - val_loss: 0.5524\n",
      "Epoch 288/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5314\n",
      "Epoch 00288: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5314 - val_loss: 0.5516\n",
      "Epoch 289/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5312\n",
      "Epoch 00289: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5312 - val_loss: 0.5521\n",
      "Epoch 290/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5312\n",
      "Epoch 00290: val_loss did not improve from 0.55095\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5312 - val_loss: 0.5526\n",
      "Epoch 00290: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.train(X_train,batch_size,epochs,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "# loss_ax.plot([hist['loss'][i] - hist['val_loss'][i] for i in range(len(hist['loss']))], 'g', label='loss - val loss')\n",
    "\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 32)\n"
     ]
    }
   ],
   "source": [
    "features = np.empty((0,32), float)\n",
    "for i in range(66):\n",
    "    features = np.append(features, autoencoder.feature_extract(X_scaled[i*30:(i+1)*30]), axis=0)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1414712856445112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "result = KMeans(n_clusters=11).fit(features)\n",
    "plotSilhouette(features,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  2  0  8  4  7  8 10  2  7  1  9  1  8  8  0  8  7  5  2  8  4  1  2\n",
      "  8  8  0  7  8  8 10  8  7  8 10 10  5  8  8  8  2  7  5  0 10  8 10  7\n",
      " 10  0  0  8  1  5  4 10 10  8 10  4  1  4 10  1 10  6  3  0  5  8  1  9\n",
      " 10  7  0 10  6 10  8  2  0  9  8 10  0  7  8 10  4  7  4 10 10  7 10  4\n",
      "  4  8  4  5  8  7  1  9  7  7  8  4  0  7  4  8  6 10 10  4  7  5  9  8\n",
      "  8  1  5  4  9 10  2  2 10  0  9  4  9  7  5  8 10  8  7 10  5  8 10  2\n",
      "  4  2  8  3  4  0  8  7  7 10  5  4  5  8  8  0  8  8  1  0  8  8  9  2\n",
      "  5  2  1  1  1  7 10  8  4  1  5  4  7  7 10  0 10  5  0  7  6  4  4 10\n",
      "  5  0  8  7  4  4  8  3  8  2  7  1 10  9  8 10  4  7  1  4  8  7  7  4\n",
      "  1  8  7  0  4 10  5  1  0  4  9  9  4  2  2  9  8  9  4  4  0  4  7  2\n",
      "  7  0  1  3  3  4  4  2  8  0  4 10  0 10 10  0  9 10  4  0  7  8  8  1\n",
      "  0  2  4  9 10  8  3  2 10  1 10  8 10  2  4  8  4  8  8  8 10 10  0 10\n",
      "  5  9 10  4 10  4  7  4  8 10  8  8  0  0  5  7  0  3  7  7 10  8  8  7\n",
      "  0  7  0  7 10  4  8  0  8  8  8  0  5  2  7  2 10  8 10  9 10  2 10  0\n",
      "  1  4 10  7  8  0 10  7  2  4 10 10  8  4  0 10  9  4 10  9  7  7  8  4\n",
      "  7 10  9  8  4  1  0  4  4  0  7  7  7  8  1  4  0  4 10  7  8  6 10  4\n",
      " 10  1  0  0  5  0  8  4  8  8 10  5  7  4 10  7  7  0  0  8  8  4  8 10\n",
      " 10 10  5  0 10  8  2  4  5  5  9  0  4  7 10  7  8  4  2  9  4  1  8  2\n",
      "  8  4  7  4  4  0  9  8  2  0  1  8  2  1  8  3  8  4  7  7  8  8  0  7\n",
      "  0  0  2 10  8  4  1  0  7  4  1 10  7  8  0  4  2  8  7  9  8  0  4  4\n",
      "  8 10  2  8  2  0  8  2  7  0 10  3  7  2 10  9 10 10  0  5  7 10  4  0\n",
      "  7  5  5  8  4  7  5  0  8  7  8 10  7  9 10  8  2  4  1  2  7  4  8  4\n",
      "  8  8 10  7  0  8  0  7  8  9  4  8  7  9  0  8  5  7 10  4 10  7  7  8\n",
      "  0  8  8  5 10 10 10 10  9  8  8 10  4  5  1 10  7  8  0 10  0  7  5  4\n",
      "  0  0 10  8  8  8  2 10  1 10  7  1  4  2  8  7  1  8  4  0  7 10  0  2\n",
      "  2 10 10 10  5  4  4  4  4 10  7 10  9  4  8 10  8  4  8 10  8  0  8  8\n",
      "  7  7  4  7 10 10  0 10  8  8  0  0  0  5  0  4  8 10  4  7  4  8  8  2\n",
      "  4  2  7  4  1  8  5  7 10  9  0  0  8  9  2 10  2  1  7 10  4  5  7  1\n",
      "  4  8  7 10 10  4 10 10  1  8  0 10  4  8  3  5  0 10  4  9  7  6  4  4\n",
      "  7  8  2  0  8  1  9  4  8  7 10  9  7  8 10  3  8 10  8  0  0  7  7 10\n",
      "  3 10  7 10  8  8 10  8  4  9  8  5  4  8  8  7  8  4  4  2  7  0  5 10\n",
      "  8  8  0  8  4  0 10  7  1  8  8  7  1  9  9  1  0  8  7  1 10  4 10  1\n",
      " 10 10  7  8  0  4  3  7  2  3  1  8  4  2  8  4  7  6  2  4  2  9  8  4\n",
      "  6 10  7  7  5  7  4  9  1  7  0  5  7 10  9  0  0 10  7  2  8  0  8  9\n",
      "  0  8  8  8 10  7  7 10  8  2  4  4 10  2  0  8  0  1  7 10  8  0  8  7\n",
      "  8  9  7  2  9  3  7  8  4  4  8 10  4  0  7  2  2 10  7  0  7 10  4  8\n",
      "  8 10  0  2  4  0 10  7 10 10  0  7  6 10  9  0  2  1  0  2  9  8  4  4\n",
      " 10  7  6  0  9  9  5  4  8  8  2  0  0  5  0  8  7  4  8  8  8  0 10 10\n",
      "  7  8  7  8  0  4  8 10  1  2 10  8  1  8  0  1  4  3  8  5  0  8  9 10\n",
      "  9  8  4  8  1  2  1  7  8  2  9  1  0  3  0  8  1  4  7  8 10  5  4  1\n",
      "  1 10  0 10  8  0  8  2  2  7  7  8  4  9  2  1  8  7  8  8  7  0  0  9\n",
      "  1  9  8 10  7  4  7  1  7 10  7  5  0  0 10  0  5  2  3  0  0  9  4 10\n",
      "  0  0  1  7  1  2  5  4 10  4 10  8  1 10  8 10  9  1  8  8  0  4  8  8\n",
      " 10  4  4  9  8  8  8  8  2  8  8  8  9  2  2  8  8  8  0  4  1  5  8  2\n",
      "  0  0  2  7  9  8  0  5  9  4 10  8  9  7  9  7  8  4  4  7  4 10  2 10\n",
      "  9  0  4  5 10  5 10  2 10 10  7  4  9  8  3  4  6  7 10  9 10  0  8  0\n",
      "  1  2  4  8  8  7 10  0  0  8  8  8  7  7  0  4  4 10  4  8 10  0  4  2\n",
      "  0  2  4 10  7  7  1  9  7  8 10  8  8  1  9  3  0  4  7  8  9  7  9  9\n",
      "  6 10  9  8  4  8  9  1 10  7  1  4 10  7  4  6  6  4  0  2  4 10  8 10\n",
      "  7  1  4  7  2  0 10  1  2  7  0 10  7  2  7  7  7 10  7  4  5  7  1  8\n",
      "  5  8  7  1  4  4  8  8  7  1  1  7  8  0 10 10  2 10 10  3  8 10  7  8\n",
      "  3  7  1  8  5  7  1  8  7  1  1  8  8  8  1  8 10  1  4  7  7  8  7  9\n",
      "  2  8  9  2  9 10  8  9  4  7  9 10  8  5  1  7  8  0  0  2  8  7  1  4\n",
      "  8  1  2  3  8  8  0  4  8  7 10  0  8  9  8  8 10  8  8  8  8  4  7  1\n",
      "  8  2  9  5  8  9  5  5  8  9  7  8  1  7  2  9  7  4  2  5  8  0  4  4\n",
      " 10  4  4  1  8  7  8  7  1  2  1  4  8  2  1  8  0 10  1  8 10 10  0  0\n",
      " 10  4  2 10  4  0  5  4  2  1  0 10  8  4  5  9 10 10  4 10  0  8  1  8\n",
      "  0  7  7  8  7 10  8  0  3  9  5  3  2  0 10 10  8  8  2  0  4  7  4  9\n",
      "  4  1 10 10 10  7  0  9  4  7 10  8  0  4  2  1  5 10  8  7  7  8  7  8\n",
      "  2  8  4  4  8  9  0  9 10  2  8  7  2  8  4  1  8  9 10  8  8  8 10  8\n",
      "  7 10 10  7  0  4  7  7 10  0  4  7  1  9  7  4  7  5 10 10  0  2 10  0\n",
      "  0  0  4  7  5  0 10  5  8  2 10  8  4  4  9 10  4  8 10  6  4  7  1 10\n",
      " 10  8  0  2  0  9  4  1  5  8  1 10 10  9  8  7  8  2  2  0  9  0  9  8\n",
      "  9  8  1  9  8 10  0  4 10  8  2 10  4  0  7  1  0  1  0 10  3  2 10  2\n",
      "  7  0  7  4  7  8  4 10  0 10  1  4  4  8  7  4  4  8  7  5 10 10  8  0\n",
      "  7  3  8  7  8  6  7  8  1  8  0  9  9  7  4  1 10  0  2 10  8  1  8  0\n",
      "  4  8 10  3 10  9 10  1  8  5  0  0  8  6  7  7  2  0  9  2  7  0  7  2\n",
      "  0  3  7 10  1  1  5 10  1 10 10  8  4  7 10  0  8  8  2  7  7  9  7  7\n",
      "  0  2  8  1  1  0  8  4  8  7  8  4  2  8  0  7  0  9  7 10 10  4  7  4\n",
      "  8  4  0  0  2  4  1 10  8  2  7  1  1  8  0  2  8  5  0  7  2  7  8  4\n",
      "  8  5  4 10  9  8  8  4  8  8 10  0  1  2  4  7  8  8 10  2  7  8 10  4\n",
      "  2  8  6 10 10  0  8  9  2  4  1  4 10  4  7  8  9  1  1  0 10  0  7  8\n",
      "  1  5 10  7  8 10  0  8 10  7  4 10  7  7  1  8  7  2 10  7  2  4  4  7\n",
      "  8  0  2  9  8  7 10  4  4 10  1  8  1 10  5  8  1  5  2  7  4 10  1  0\n",
      "  1  7  0  9  9  4 10  8 10  8  7  5  2  9  4  2  4  8 10  0  8  9  9  8\n",
      "  0 10  7  0 10  9  0  7  8  9  2  7  6  4  8 10 10  7  8  4  2  7  4  2\n",
      "  4  1  3  0  4  8  3 10  2  2  7  8  7  2  7  8  8 10 10  5  0  9  7  7\n",
      "  0  4  8  7  8  0  1  4  4  9  7  4  0 10  8  0  8  8  7  0  2  8  4  7\n",
      "  2 10  0  0  4  4  0  9  8  5  7  4  1  8 10  4 10  0  5  8  2  8  8  7\n",
      "  7  8 10 10  0  2 10  8  7  7  8  4  0  4 10  4  5  6 10  8  7  8  7  8\n",
      "  7 10  5  8 10  4  8  7  4  7  8  4 10  8  9  8  4  0 10 10 10  7  0  8\n",
      "  9 10 10  0 10  2  8  8 10  2 10  8 10  8  0 10  4  4  0 10  9  4  6  4\n",
      "  5 10  2 10  4  7 10  2  1  5  5  0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "print(result.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score\n",
    "from matplotlib import cm\n",
    "\n",
    "def plotSilhouette(X, y_km):\n",
    "    cluster_labels = np.unique(y_km.labels_)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_score(X, y_km.labels_,metric='euclidean')\n",
    "    print(silhouette_vals)\n",
    "#     y_ax_lower, y_ax_upper = 0,0\n",
    "#     yticks = []\n",
    "    \n",
    "#     for i , c in enumerate(cluster_labels):\n",
    "#         c_silhouette_vals = silhouette_vals[y_km.labels_ == c]\n",
    "#         c_silhouette_vals.sort()\n",
    "#         y_ax_upper += len(c_silhouette_vals)\n",
    "#         color = cm.jet(i/n_clusters)\n",
    "        \n",
    "#         plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0,edgecolor='none', color=color)\n",
    "#         yticks.append((y_ax_lower + y_ax_upper)/2)\n",
    "#         y_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "#     silhouette_avg = np.mean(silhouette_vals)\n",
    "#     plt.axvline(silhouette_avg, color='red', linestyle='--')\n",
    "#     plt.yticks(yticks, cluster_labels+1)\n",
    "#     plt.ylabel('cluster')\n",
    "#     plt.xlabel('silhouette score')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2279039883123083\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"insect_128_8_bce.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
