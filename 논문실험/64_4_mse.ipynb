{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f = open('resources/InsectWingbeatSound/InsectWingbeatSound_TEST','r')\n",
    "data = f.read()\n",
    "f.close()\n",
    "# 개행문자 기준으로 끊어서 리스트로\n",
    "data_list = data.split('\\n')\n",
    "\n",
    "# \",\" 기준으로 끊어서 리스트로\n",
    "emptylist = []\n",
    "for list_part in data_list:\n",
    "    emptylist.append(list_part.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str -> float 변환\n",
    "tofloat = []\n",
    "for partlist in emptylist:\n",
    "    tofloat.append([float(i) for i in partlist]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980,)\n",
      "(1980, 256)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "data_list = []\n",
    "for datas in tofloat:\n",
    "    labels.append(datas[0])\n",
    "    data_list.append(datas[1:])\n",
    "print(np.shape(labels))\n",
    "print(np.shape(data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readFile import split_into_values, toRPdata\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler\n",
    "\n",
    "def Standard(data):\n",
    "    SS = StandardScaler().fit(data)\n",
    "    scaled = SS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "def MinMax(data):\n",
    "    MMS = MinMaxScaler().fit(data)\n",
    "    scaled = MMS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "# result_list transpose\n",
    "result_T = [list(x) for x in zip(*data_list)]\n",
    "\n",
    "# minmax 정규화\n",
    "result_scaled = Standard(result_T)\n",
    "\n",
    "# 다시 result transpose 해서 원래대로\n",
    "result_scaled = [list(x) for x in zip(*result_scaled)]\n",
    "\n",
    "result_ = np.array(result_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256, 256, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = result_.reshape(result_.shape[0], 1, result_.shape[1])\n",
    "X = toRPdata(data, threshold='point', percentage=30)\n",
    "#X = toRPdata(data)\n",
    "    \n",
    "X_scaled = np.expand_dims(X, axis=3)\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x152a3240828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-5\n",
    "optimizer='Adam'\n",
    "loss='mse'\n",
    "image_size = 256 #1024, 256\n",
    "dimension = 4 # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 64)      640       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      18464     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 16)        4624      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 1)         145       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 1)           10        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 1)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 256, 1)       577       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256, 256, 1)       0         \n",
      "=================================================================\n",
      "Total params: 47,756\n",
      "Trainable params: 47,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from utils import split_data, normalization_tool\n",
    "from agent import Autoencoder_Agent\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_data(X_scaled, X_scaled) #데이터 분리\n",
    "\n",
    "autoencoder = Autoencoder_Agent(model_size=image_size, dimension=dimension, optimizer=optimizer,learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.2314\n",
      "Epoch 00001: val_loss improved from inf to 0.21231, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.2314 - val_loss: 0.2123\n",
      "Epoch 2/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2104\n",
      "Epoch 00002: val_loss improved from 0.21231 to 0.20891, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.2104 - val_loss: 0.2089\n",
      "Epoch 3/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2077\n",
      "Epoch 00003: val_loss improved from 0.20891 to 0.20665, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.2077 - val_loss: 0.2066\n",
      "Epoch 4/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2058\n",
      "Epoch 00004: val_loss improved from 0.20665 to 0.20491, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.2057 - val_loss: 0.2049\n",
      "Epoch 5/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2040\n",
      "Epoch 00005: val_loss improved from 0.20491 to 0.20262, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.2040 - val_loss: 0.2026\n",
      "Epoch 6/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2016\n",
      "Epoch 00006: val_loss improved from 0.20262 to 0.20014, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.2016 - val_loss: 0.2001\n",
      "Epoch 7/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1995\n",
      "Epoch 00007: val_loss improved from 0.20014 to 0.19845, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1994 - val_loss: 0.1984\n",
      "Epoch 8/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1981\n",
      "Epoch 00008: val_loss improved from 0.19845 to 0.19746, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1981 - val_loss: 0.1975\n",
      "Epoch 9/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1974\n",
      "Epoch 00009: val_loss improved from 0.19746 to 0.19689, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1974 - val_loss: 0.1969\n",
      "Epoch 10/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1969\n",
      "Epoch 00010: val_loss improved from 0.19689 to 0.19654, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1969 - val_loss: 0.1965\n",
      "Epoch 11/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1966\n",
      "Epoch 00011: val_loss improved from 0.19654 to 0.19634, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1966 - val_loss: 0.1963\n",
      "Epoch 12/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1963\n",
      "Epoch 00012: val_loss improved from 0.19634 to 0.19605, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1963 - val_loss: 0.1960\n",
      "Epoch 13/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1961\n",
      "Epoch 00013: val_loss improved from 0.19605 to 0.19586, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1961 - val_loss: 0.1959\n",
      "Epoch 14/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1958\n",
      "Epoch 00014: val_loss improved from 0.19586 to 0.19573, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1958 - val_loss: 0.1957\n",
      "Epoch 15/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1956\n",
      "Epoch 00015: val_loss improved from 0.19573 to 0.19572, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1956 - val_loss: 0.1957\n",
      "Epoch 16/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1955\n",
      "Epoch 00016: val_loss improved from 0.19572 to 0.19552, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1954 - val_loss: 0.1955\n",
      "Epoch 17/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1953\n",
      "Epoch 00017: val_loss improved from 0.19552 to 0.19540, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1953 - val_loss: 0.1954\n",
      "Epoch 18/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1951\n",
      "Epoch 00018: val_loss improved from 0.19540 to 0.19531, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1952 - val_loss: 0.1953\n",
      "Epoch 19/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1951\n",
      "Epoch 00019: val_loss improved from 0.19531 to 0.19522, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1951 - val_loss: 0.1952\n",
      "Epoch 20/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1949\n",
      "Epoch 00020: val_loss improved from 0.19522 to 0.19512, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1950 - val_loss: 0.1951\n",
      "Epoch 21/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1949\n",
      "Epoch 00021: val_loss improved from 0.19512 to 0.19504, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1949 - val_loss: 0.1950\n",
      "Epoch 22/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1948- ETA: 0s - loss: 0\n",
      "Epoch 00022: val_loss improved from 0.19504 to 0.19498, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1948 - val_loss: 0.1950\n",
      "Epoch 23/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1948\n",
      "Epoch 00023: val_loss improved from 0.19498 to 0.19495, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1947 - val_loss: 0.1949\n",
      "Epoch 24/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1947\n",
      "Epoch 00024: val_loss did not improve from 0.19495\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1946 - val_loss: 0.1950\n",
      "Epoch 25/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1945\n",
      "Epoch 00025: val_loss improved from 0.19495 to 0.19491, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1946 - val_loss: 0.1949\n",
      "Epoch 26/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1945\n",
      "Epoch 00026: val_loss improved from 0.19491 to 0.19488, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1945 - val_loss: 0.1949\n",
      "Epoch 27/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1944\n",
      "Epoch 00027: val_loss improved from 0.19488 to 0.19485, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1944 - val_loss: 0.1949\n",
      "Epoch 28/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1944\n",
      "Epoch 00028: val_loss improved from 0.19485 to 0.19476, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1944 - val_loss: 0.1948\n",
      "Epoch 29/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1942\n",
      "Epoch 00029: val_loss did not improve from 0.19476\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1943 - val_loss: 0.1948\n",
      "Epoch 30/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1943\n",
      "Epoch 00030: val_loss improved from 0.19476 to 0.19467, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1943 - val_loss: 0.1947\n",
      "Epoch 31/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1942\n",
      "Epoch 00031: val_loss improved from 0.19467 to 0.19462, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1942 - val_loss: 0.1946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1941\n",
      "Epoch 00032: val_loss improved from 0.19462 to 0.19460, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1941 - val_loss: 0.1946\n",
      "Epoch 33/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1940\n",
      "Epoch 00033: val_loss improved from 0.19460 to 0.19456, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1941 - val_loss: 0.1946\n",
      "Epoch 34/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1940\n",
      "Epoch 00034: val_loss improved from 0.19456 to 0.19454, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1940 - val_loss: 0.1945\n",
      "Epoch 35/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1940\n",
      "Epoch 00035: val_loss did not improve from 0.19454\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1940 - val_loss: 0.1945\n",
      "Epoch 36/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1940\n",
      "Epoch 00036: val_loss did not improve from 0.19454\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1939 - val_loss: 0.1946\n",
      "Epoch 37/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1939\n",
      "Epoch 00037: val_loss improved from 0.19454 to 0.19447, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1940 - val_loss: 0.1945\n",
      "Epoch 38/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1939\n",
      "Epoch 00038: val_loss did not improve from 0.19447\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1938 - val_loss: 0.1945\n",
      "Epoch 39/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1938\n",
      "Epoch 00039: val_loss did not improve from 0.19447\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1938 - val_loss: 0.1945\n",
      "Epoch 40/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1938\n",
      "Epoch 00040: val_loss improved from 0.19447 to 0.19441, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1938 - val_loss: 0.1944\n",
      "Epoch 41/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1938\n",
      "Epoch 00041: val_loss did not improve from 0.19441\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1937 - val_loss: 0.1945\n",
      "Epoch 42/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1936\n",
      "Epoch 00042: val_loss did not improve from 0.19441\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1936 - val_loss: 0.1945\n",
      "Epoch 43/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1936\n",
      "Epoch 00043: val_loss did not improve from 0.19441\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1936 - val_loss: 0.1944\n",
      "Epoch 44/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1935\n",
      "Epoch 00044: val_loss did not improve from 0.19441\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1936 - val_loss: 0.1945\n",
      "Epoch 45/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1936- ET\n",
      "Epoch 00045: val_loss improved from 0.19441 to 0.19439, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1936 - val_loss: 0.1944\n",
      "Epoch 46/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1935\n",
      "Epoch 00046: val_loss improved from 0.19439 to 0.19438, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1935 - val_loss: 0.1944\n",
      "Epoch 47/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1935\n",
      "Epoch 00047: val_loss improved from 0.19438 to 0.19437, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1935 - val_loss: 0.1944\n",
      "Epoch 48/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1935\n",
      "Epoch 00048: val_loss improved from 0.19437 to 0.19436, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1935 - val_loss: 0.1944\n",
      "Epoch 49/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1934\n",
      "Epoch 00049: val_loss did not improve from 0.19436\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1934 - val_loss: 0.1944\n",
      "Epoch 50/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1934\n",
      "Epoch 00050: val_loss did not improve from 0.19436\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1934 - val_loss: 0.1944\n",
      "Epoch 51/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1933\n",
      "Epoch 00051: val_loss did not improve from 0.19436\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1933 - val_loss: 0.1946\n",
      "Epoch 52/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1933\n",
      "Epoch 00052: val_loss improved from 0.19436 to 0.19434, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1933 - val_loss: 0.1943\n",
      "Epoch 53/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1933\n",
      "Epoch 00053: val_loss improved from 0.19434 to 0.19433, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1933 - val_loss: 0.1943\n",
      "Epoch 54/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1933\n",
      "Epoch 00054: val_loss improved from 0.19433 to 0.19421, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1933 - val_loss: 0.1942\n",
      "Epoch 55/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1932\n",
      "Epoch 00055: val_loss did not improve from 0.19421\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1933 - val_loss: 0.1942\n",
      "Epoch 56/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1931\n",
      "Epoch 00056: val_loss improved from 0.19421 to 0.19421, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1932 - val_loss: 0.1942\n",
      "Epoch 57/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1931\n",
      "Epoch 00057: val_loss did not improve from 0.19421\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1932 - val_loss: 0.1942\n",
      "Epoch 58/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1931\n",
      "Epoch 00058: val_loss improved from 0.19421 to 0.19416, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1931 - val_loss: 0.1942\n",
      "Epoch 59/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1931\n",
      "Epoch 00059: val_loss did not improve from 0.19416\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1931 - val_loss: 0.1942\n",
      "Epoch 60/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1932\n",
      "Epoch 00060: val_loss improved from 0.19416 to 0.19416, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1930 - val_loss: 0.1942\n",
      "Epoch 61/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1931\n",
      "Epoch 00061: val_loss improved from 0.19416 to 0.19410, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1931 - val_loss: 0.1941\n",
      "Epoch 62/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1931\n",
      "Epoch 00062: val_loss did not improve from 0.19410\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1930 - val_loss: 0.1941\n",
      "Epoch 63/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1930\n",
      "Epoch 00063: val_loss did not improve from 0.19410\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1930 - val_loss: 0.1942\n",
      "Epoch 64/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1931\n",
      "Epoch 00064: val_loss improved from 0.19410 to 0.19409, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1930 - val_loss: 0.1941\n",
      "Epoch 65/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/149 [============================>.] - ETA: 0s - loss: 0.1930\n",
      "Epoch 00065: val_loss improved from 0.19409 to 0.19405, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1929 - val_loss: 0.1941\n",
      "Epoch 66/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1929\n",
      "Epoch 00066: val_loss did not improve from 0.19405\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1929 - val_loss: 0.1941\n",
      "Epoch 67/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1930\n",
      "Epoch 00067: val_loss did not improve from 0.19405\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1929 - val_loss: 0.1941\n",
      "Epoch 68/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1929\n",
      "Epoch 00068: val_loss improved from 0.19405 to 0.19403, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1929 - val_loss: 0.1940\n",
      "Epoch 69/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1928\n",
      "Epoch 00069: val_loss did not improve from 0.19403\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1929 - val_loss: 0.1940\n",
      "Epoch 70/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1928\n",
      "Epoch 00070: val_loss improved from 0.19403 to 0.19395, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1928 - val_loss: 0.1940\n",
      "Epoch 71/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1928\n",
      "Epoch 00071: val_loss did not improve from 0.19395\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1928 - val_loss: 0.1940\n",
      "Epoch 72/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1928\n",
      "Epoch 00072: val_loss did not improve from 0.19395\n",
      "149/149 [==============================] - 12s 80ms/step - loss: 0.1928 - val_loss: 0.1940\n",
      "Epoch 73/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1928\n",
      "Epoch 00073: val_loss did not improve from 0.19395\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1928 - val_loss: 0.1940\n",
      "Epoch 74/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1928\n",
      "Epoch 00074: val_loss did not improve from 0.19395\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1928 - val_loss: 0.1941\n",
      "Epoch 75/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1928\n",
      "Epoch 00075: val_loss improved from 0.19395 to 0.19392, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 80ms/step - loss: 0.1928 - val_loss: 0.1939\n",
      "Epoch 76/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1928\n",
      "Epoch 00076: val_loss did not improve from 0.19392\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1927 - val_loss: 0.1941\n",
      "Epoch 77/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1927\n",
      "Epoch 00077: val_loss did not improve from 0.19392\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1927 - val_loss: 0.1940\n",
      "Epoch 78/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1927\n",
      "Epoch 00078: val_loss improved from 0.19392 to 0.19391, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1927 - val_loss: 0.1939\n",
      "Epoch 79/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1927\n",
      "Epoch 00079: val_loss did not improve from 0.19391\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1927 - val_loss: 0.1940\n",
      "Epoch 80/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1926\n",
      "Epoch 00080: val_loss improved from 0.19391 to 0.19389, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1927 - val_loss: 0.1939\n",
      "Epoch 81/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1926\n",
      "Epoch 00081: val_loss improved from 0.19389 to 0.19389, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1927 - val_loss: 0.1939\n",
      "Epoch 82/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1926\n",
      "Epoch 00082: val_loss did not improve from 0.19389\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1926 - val_loss: 0.1941\n",
      "Epoch 83/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1926\n",
      "Epoch 00083: val_loss improved from 0.19389 to 0.19382, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.1926 - val_loss: 0.1938\n",
      "Epoch 84/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1926\n",
      "Epoch 00084: val_loss did not improve from 0.19382\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1926 - val_loss: 0.1939\n",
      "Epoch 85/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1926\n",
      "Epoch 00085: val_loss did not improve from 0.19382\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1926 - val_loss: 0.1939\n",
      "Epoch 86/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1926\n",
      "Epoch 00086: val_loss did not improve from 0.19382\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1926 - val_loss: 0.1941\n",
      "Epoch 87/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1925\n",
      "Epoch 00087: val_loss improved from 0.19382 to 0.19382, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1925 - val_loss: 0.1938\n",
      "Epoch 88/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1925\n",
      "Epoch 00088: val_loss did not improve from 0.19382\n",
      "149/149 [==============================] - 12s 80ms/step - loss: 0.1925 - val_loss: 0.1940\n",
      "Epoch 89/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1926\n",
      "Epoch 00089: val_loss did not improve from 0.19382\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1925 - val_loss: 0.1939\n",
      "Epoch 90/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1925\n",
      "Epoch 00090: val_loss improved from 0.19382 to 0.19381, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.1925 - val_loss: 0.1938\n",
      "Epoch 91/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1925\n",
      "Epoch 00091: val_loss improved from 0.19381 to 0.19381, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1924 - val_loss: 0.1938\n",
      "Epoch 92/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1925\n",
      "Epoch 00092: val_loss improved from 0.19381 to 0.19377, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1925 - val_loss: 0.1938\n",
      "Epoch 93/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1925- ETA: 0s - \n",
      "Epoch 00093: val_loss did not improve from 0.19377\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1924 - val_loss: 0.1938\n",
      "Epoch 94/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1924\n",
      "Epoch 00094: val_loss did not improve from 0.19377\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1924 - val_loss: 0.1938\n",
      "Epoch 95/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1924\n",
      "Epoch 00095: val_loss improved from 0.19377 to 0.19374, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1924 - val_loss: 0.1937\n",
      "Epoch 96/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1923\n",
      "Epoch 00096: val_loss did not improve from 0.19374\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1924 - val_loss: 0.1938\n",
      "Epoch 97/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1924\n",
      "Epoch 00097: val_loss improved from 0.19374 to 0.19372, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1923 - val_loss: 0.1937\n",
      "Epoch 98/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1923\n",
      "Epoch 00098: val_loss did not improve from 0.19372\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1923 - val_loss: 0.1938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1923\n",
      "Epoch 00099: val_loss improved from 0.19372 to 0.19366, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1923 - val_loss: 0.1937\n",
      "Epoch 100/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1923\n",
      "Epoch 00100: val_loss did not improve from 0.19366\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1923 - val_loss: 0.1937\n",
      "Epoch 101/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1923\n",
      "Epoch 00101: val_loss did not improve from 0.19366\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1923 - val_loss: 0.1937\n",
      "Epoch 102/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1923\n",
      "Epoch 00102: val_loss did not improve from 0.19366\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1923 - val_loss: 0.1940\n",
      "Epoch 103/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1923\n",
      "Epoch 00103: val_loss did not improve from 0.19366\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1923 - val_loss: 0.1937\n",
      "Epoch 104/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1922\n",
      "Epoch 00104: val_loss did not improve from 0.19366\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1922 - val_loss: 0.1938\n",
      "Epoch 105/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1922\n",
      "Epoch 00105: val_loss did not improve from 0.19366\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1922 - val_loss: 0.1937\n",
      "Epoch 106/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1922\n",
      "Epoch 00106: val_loss did not improve from 0.19366\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1922 - val_loss: 0.1938\n",
      "Epoch 107/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1922\n",
      "Epoch 00107: val_loss improved from 0.19366 to 0.19361, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.1922 - val_loss: 0.1936\n",
      "Epoch 108/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1921\n",
      "Epoch 00108: val_loss improved from 0.19361 to 0.19360, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.1922 - val_loss: 0.1936\n",
      "Epoch 109/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1922\n",
      "Epoch 00109: val_loss did not improve from 0.19360\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.1922 - val_loss: 0.1937\n",
      "Epoch 110/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1922\n",
      "Epoch 00110: val_loss did not improve from 0.19360\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.1922 - val_loss: 0.1936\n",
      "Epoch 111/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1921\n",
      "Epoch 00111: val_loss did not improve from 0.19360\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1921 - val_loss: 0.1936\n",
      "Epoch 112/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1921\n",
      "Epoch 00112: val_loss did not improve from 0.19360\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1921 - val_loss: 0.1936\n",
      "Epoch 113/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1921\n",
      "Epoch 00113: val_loss improved from 0.19360 to 0.19357, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1921 - val_loss: 0.1936\n",
      "Epoch 114/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1920\n",
      "Epoch 00114: val_loss improved from 0.19357 to 0.19349, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1921 - val_loss: 0.1935\n",
      "Epoch 115/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1921\n",
      "Epoch 00115: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1921 - val_loss: 0.1935\n",
      "Epoch 116/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1921\n",
      "Epoch 00116: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1921 - val_loss: 0.1935\n",
      "Epoch 117/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.1920\n",
      "Epoch 00117: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1920 - val_loss: 0.1936\n",
      "Epoch 118/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1921\n",
      "Epoch 00118: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1921 - val_loss: 0.1936\n",
      "Epoch 119/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1921\n",
      "Epoch 00119: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1920 - val_loss: 0.1936\n",
      "Epoch 120/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1920\n",
      "Epoch 00120: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1920 - val_loss: 0.1935\n",
      "Epoch 121/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1920\n",
      "Epoch 00121: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1920 - val_loss: 0.1936\n",
      "Epoch 122/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1920\n",
      "Epoch 00122: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1920 - val_loss: 0.1936\n",
      "Epoch 123/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1919\n",
      "Epoch 00123: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1920 - val_loss: 0.1935\n",
      "Epoch 124/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1920\n",
      "Epoch 00124: val_loss did not improve from 0.19349\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1920 - val_loss: 0.1935\n",
      "Epoch 125/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1919\n",
      "Epoch 00125: val_loss improved from 0.19349 to 0.19345, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1919 - val_loss: 0.1935\n",
      "Epoch 126/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00126: val_loss did not improve from 0.19345\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1919 - val_loss: 0.1936\n",
      "Epoch 127/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1919\n",
      "Epoch 00127: val_loss did not improve from 0.19345\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1919 - val_loss: 0.1936\n",
      "Epoch 128/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1919\n",
      "Epoch 00128: val_loss did not improve from 0.19345\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1919 - val_loss: 0.1937\n",
      "Epoch 129/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00129: val_loss improved from 0.19345 to 0.19344, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1919 - val_loss: 0.1934\n",
      "Epoch 130/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1919\n",
      "Epoch 00130: val_loss did not improve from 0.19344\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1918 - val_loss: 0.1934\n",
      "Epoch 131/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00131: val_loss did not improve from 0.19344\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1918 - val_loss: 0.1935\n",
      "Epoch 132/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1919\n",
      "Epoch 00132: val_loss did not improve from 0.19344\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1919 - val_loss: 0.1934\n",
      "Epoch 133/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00133: val_loss improved from 0.19344 to 0.19343, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1919 - val_loss: 0.1934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00134: val_loss improved from 0.19343 to 0.19342, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1918 - val_loss: 0.1934\n",
      "Epoch 135/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00135: val_loss did not improve from 0.19342\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1918 - val_loss: 0.1935\n",
      "Epoch 136/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00136: val_loss did not improve from 0.19342\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1918 - val_loss: 0.1936\n",
      "Epoch 137/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00137: val_loss did not improve from 0.19342\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1918 - val_loss: 0.1935\n",
      "Epoch 138/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00138: val_loss did not improve from 0.19342\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1917 - val_loss: 0.1936\n",
      "Epoch 139/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Epoch 00139: val_loss did not improve from 0.19342\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1917 - val_loss: 0.1935\n",
      "Epoch 140/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Epoch 00140: val_loss did not improve from 0.19342\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1917 - val_loss: 0.1936\n",
      "Epoch 141/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Epoch 00141: val_loss improved from 0.19342 to 0.19339, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1917 - val_loss: 0.1934\n",
      "Epoch 142/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Epoch 00142: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1917 - val_loss: 0.1934\n",
      "Epoch 143/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00143: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1917 - val_loss: 0.1935\n",
      "Epoch 144/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Epoch 00144: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1917 - val_loss: 0.1934\n",
      "Epoch 145/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00145: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1916 - val_loss: 0.1934\n",
      "Epoch 146/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Epoch 00146: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1917 - val_loss: 0.1935\n",
      "Epoch 147/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Epoch 00147: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1917 - val_loss: 0.1936\n",
      "Epoch 148/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Epoch 00148: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1916 - val_loss: 0.1935\n",
      "Epoch 149/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00149: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1916 - val_loss: 0.1936\n",
      "Epoch 150/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Epoch 00150: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1916 - val_loss: 0.1936\n",
      "Epoch 151/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00151: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1916 - val_loss: 0.1934\n",
      "Epoch 152/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00152: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1916 - val_loss: 0.1935\n",
      "Epoch 153/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00153: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1916 - val_loss: 0.1935\n",
      "Epoch 154/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00154: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1934\n",
      "Epoch 155/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00155: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1916 - val_loss: 0.1935\n",
      "Epoch 156/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00156: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1916 - val_loss: 0.1934\n",
      "Epoch 157/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00157: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1934\n",
      "Epoch 158/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00158: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1916 - val_loss: 0.1935\n",
      "Epoch 159/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00159: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1916 - val_loss: 0.1936\n",
      "Epoch 160/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00160: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1935\n",
      "Epoch 161/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1916\n",
      "Epoch 00161: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1934\n",
      "Epoch 162/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00162: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1935\n",
      "Epoch 163/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00163: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1936\n",
      "Epoch 164/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00164: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1936\n",
      "Epoch 165/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1914\n",
      "Epoch 00165: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1935\n",
      "Epoch 166/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00166: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1936\n",
      "Epoch 167/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00167: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1914 - val_loss: 0.1935\n",
      "Epoch 168/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1914\n",
      "Epoch 00168: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1914 - val_loss: 0.1934\n",
      "Epoch 169/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1915\n",
      "Epoch 00169: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1914 - val_loss: 0.1935\n",
      "Epoch 170/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/149 [============================>.] - ETA: 0s - loss: 0.1914\n",
      "Epoch 00170: val_loss did not improve from 0.19339\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1915 - val_loss: 0.1935\n",
      "Epoch 171/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1914\n",
      "Epoch 00171: val_loss improved from 0.19339 to 0.19337, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1914 - val_loss: 0.1934\n",
      "Epoch 172/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1914\n",
      "Epoch 00172: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1914 - val_loss: 0.1934\n",
      "Epoch 173/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1914\n",
      "Epoch 00173: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1914 - val_loss: 0.1935\n",
      "Epoch 174/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00174: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1914 - val_loss: 0.1935\n",
      "Epoch 175/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00175: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 77ms/step - loss: 0.1913 - val_loss: 0.1935\n",
      "Epoch 176/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1914- ETA: 0s - loss: 0.1\n",
      "Epoch 00176: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1913 - val_loss: 0.1935\n",
      "Epoch 177/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00177: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1913 - val_loss: 0.1935\n",
      "Epoch 178/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1914\n",
      "Epoch 00178: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1914 - val_loss: 0.1935\n",
      "Epoch 179/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00179: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1913 - val_loss: 0.1935\n",
      "Epoch 180/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00180: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1913 - val_loss: 0.1937\n",
      "Epoch 181/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00181: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1913 - val_loss: 0.1935\n",
      "Epoch 182/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00182: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1913 - val_loss: 0.1936\n",
      "Epoch 183/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00183: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1913 - val_loss: 0.1935\n",
      "Epoch 184/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00184: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.1913 - val_loss: 0.1935\n",
      "Epoch 185/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00185: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.1912 - val_loss: 0.1936\n",
      "Epoch 186/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00186: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.1913 - val_loss: 0.1934\n",
      "Epoch 187/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1912\n",
      "Epoch 00187: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.1912 - val_loss: 0.1935\n",
      "Epoch 188/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00188: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1913 - val_loss: 0.1936\n",
      "Epoch 189/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1912\n",
      "Epoch 00189: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 0.1912 - val_loss: 0.1935\n",
      "Epoch 190/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1912\n",
      "Epoch 00190: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1912 - val_loss: 0.1935\n",
      "Epoch 191/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1912\n",
      "Epoch 00191: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1912 - val_loss: 0.1936\n",
      "Epoch 192/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00192: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1912 - val_loss: 0.1936\n",
      "Epoch 193/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1912\n",
      "Epoch 00193: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1912 - val_loss: 0.1934\n",
      "Epoch 194/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00194: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1912 - val_loss: 0.1934\n",
      "Epoch 195/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1912\n",
      "Epoch 00195: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1912 - val_loss: 0.1936\n",
      "Epoch 196/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1912\n",
      "Epoch 00196: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1912 - val_loss: 0.1935\n",
      "Epoch 197/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00197: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1911 - val_loss: 0.1935\n",
      "Epoch 198/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00198: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 0.1912 - val_loss: 0.1940\n",
      "Epoch 199/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1912\n",
      "Epoch 00199: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1912 - val_loss: 0.1936\n",
      "Epoch 200/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00200: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1912 - val_loss: 0.1935\n",
      "Epoch 201/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1912- ETA: 0s - los\n",
      "Epoch 00201: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1911 - val_loss: 0.1935\n",
      "Epoch 202/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00202: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1912 - val_loss: 0.1935\n",
      "Epoch 203/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00203: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1911 - val_loss: 0.1935\n",
      "Epoch 204/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911- ET\n",
      "Epoch 00204: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1911 - val_loss: 0.1935\n",
      "Epoch 205/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00205: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1911 - val_loss: 0.1935\n",
      "Epoch 206/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00206: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1911 - val_loss: 0.1934\n",
      "Epoch 207/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00207: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1911 - val_loss: 0.1935\n",
      "Epoch 208/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00208: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1911 - val_loss: 0.1936\n",
      "Epoch 209/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00209: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 0.1910 - val_loss: 0.1936\n",
      "Epoch 210/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00210: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1936\n",
      "Epoch 211/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00211: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1936\n",
      "Epoch 212/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00212: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1937\n",
      "Epoch 213/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00213: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1936\n",
      "Epoch 214/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00214: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1936\n",
      "Epoch 215/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00215: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1937\n",
      "Epoch 216/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00216: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1936\n",
      "Epoch 217/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00217: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1935\n",
      "Epoch 218/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.1910\n",
      "Epoch 00218: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1936\n",
      "Epoch 219/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1911\n",
      "Epoch 00219: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1936\n",
      "Epoch 220/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00220: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1936\n",
      "Epoch 221/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00221: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1910 - val_loss: 0.1937\n",
      "Epoch 222/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00222: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1936\n",
      "Epoch 223/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00223: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1936\n",
      "Epoch 224/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1910\n",
      "Epoch 00224: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1936\n",
      "Epoch 225/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00225: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1936\n",
      "Epoch 226/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00226: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1936\n",
      "Epoch 227/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909- ET\n",
      "Epoch 00227: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1937\n",
      "Epoch 228/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00228: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1936\n",
      "Epoch 229/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00229: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1936\n",
      "Epoch 230/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00230: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1937\n",
      "Epoch 231/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00231: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1937\n",
      "Epoch 232/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00232: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1937\n",
      "Epoch 233/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1908\n",
      "Epoch 00233: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1939\n",
      "Epoch 234/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1908\n",
      "Epoch 00234: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1936\n",
      "Epoch 235/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1908\n",
      "Epoch 00235: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1908 - val_loss: 0.1936\n",
      "Epoch 236/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1908\n",
      "Epoch 00236: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1936\n",
      "Epoch 237/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1908\n",
      "Epoch 00237: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1909 - val_loss: 0.1937\n",
      "Epoch 238/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00238: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1908 - val_loss: 0.1936\n",
      "Epoch 239/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1908\n",
      "Epoch 00239: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1908 - val_loss: 0.1936\n",
      "Epoch 240/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00240: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1908 - val_loss: 0.1937\n",
      "Epoch 241/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.1908\n",
      "Epoch 00241: val_loss did not improve from 0.19337\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 0.1908 - val_loss: 0.1935\n",
      "Epoch 00241: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.train(X_train,batch_size,epochs,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "# loss_ax.plot([hist['loss'][i] - hist['val_loss'][i] for i in range(len(hist['loss']))], 'g', label='loss - val loss')\n",
    "\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 4)\n"
     ]
    }
   ],
   "source": [
    "features = np.empty((0,4), float)\n",
    "for i in range(66):\n",
    "    features = np.append(features, autoencoder.feature_extract(X_scaled[i*30:(i+1)*30]), axis=0)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "result = KMeans(n_clusters=11).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  7  1  4  2  1  2 10  8  3  4  6  9  3 10  1  7  7  8  5  1  4  5  5\n",
      "  1  2  1  2  3  3  3 10  1  1 10  3  0  2  1  7  8  1  8  2  7  7  1  7\n",
      "  7  2  1  3  6  6  6  1 10  1 10  1  2  3 10  4  7  9  8  3  8  3  5  8\n",
      "  3  3  1 10  0  2  2  5  7  9  1 10  7  2  1  7  2  1  4  7 10  3  7  2\n",
      "  2  2  1  8  1  1  4  9  2 10  2  3  7  2  2  3  8  3  3  3  1  6  0  1\n",
      "  3  5  8  2  5  1  2  4  3  7  5  1  5  4  8  7 10  2  4  3  8  1 10  8\n",
      "  6  5  7  8  4  1  1  1  1  1  8  2  4  7  2  1  1  1  5  2  1  1  0  6\n",
      "  6  4  4  5  5  7  7  3  1  2  8  2  1  1 10  3  7  8  2  3  9  4  4 10\n",
      "  8  7  2 10  2  4  3  0  7  6  3  6  7  0  3 10  1  7  5  5  6  2  1  6\n",
      "  6 10 10 10  2 10  8  6  1  2  9  5  1  4  7  5  1  5  2  2  7  6  2  6\n",
      "  1 10  4  0  0  4  2  6  7  7  3  7  3  3  1  3  0 10  1  7  4  2  3  4\n",
      "  4  7  1  5  7  3  0  4  7  2  2  3  7  1  6  7  2  1  7  1  1  7  1  2\n",
      "  6  5  1  3  1  7  7  4  1  3  1  1  7  3  4  2  1  0  1  1  7  2  7  3\n",
      "  3  5  7  1 10  6  7  7  7  1  3  7  0  2  1  9 10  3 10  9 10  4 10  1\n",
      "  5  3  7  3  3  7  7  2  4  4  3  2  3  4  4 10  9  4  3  5  2  3  1  1\n",
      "  2 10  9 10  7  5  1  5  4  1  7  3  1 10  6  6  1  1  1  2  1  9  1  2\n",
      "  3  9  1  1  8  7  2 10  3  2  3  6  1  2  7  2  1  6  1  7  2  1 10  3\n",
      "  3 10  8 10 10  1  7  9  8  0  9  1  1  2  3  4 10  6  2  4  8  2  7  1\n",
      "  6  2  1  2  4  4  5  2  4  1  9  1  1  5  2  0  1  1  1  4 10  7  1  1\n",
      "  1  7  2  7  1  6  4  2  6  1  6  7  4  3  2  7  4  3  2  9  2  2  4  3\n",
      "  2  7  1  2  9  2  2  4  7  1  7  8  1  5  3  4  2  2  4  5  2  7  5 10\n",
      "  2  8  8  1  2  1  1  7  1  7  2  2  3  4  1  2  4  2  4  1  4 10  1  1\n",
      "  1  7  7  3  7 10  1  3  1  5  2  3  1  0  7  1  8  3  1  4  7  1  2  1\n",
      "  3  2  3  8  3 10  7  7  5  7  3 10 10  8  4  3  1  1  1 10  1  2  8  4\n",
      "  2  7  1  7  7  2  4  7  6  3  2  5  6  5 10  1  2  1  2  2  1  7  7  6\n",
      "  1 10  3 10  9  2  3  6  2  7  2  7  2  4  3 10  2  4  6  3  7  2  1 10\n",
      "  3  2  3  6  3 10  7  3  7  1  3  7  7  5  7  2  3  7  2  1  1  3 10  8\n",
      "  2  7  2  4  5  3  8  1 10  0  1  7  7  8  2  3  8  2  1  7  2  2  1  4\n",
      "  4  1  2  1  1  1  7 10  2  2  1  7  3  7  0  8  7 10  2  5 10  8  1  1\n",
      "  2  8  2  1  3  5  0  3  1  1  3  9  1  1 10  0 10 10  3  7  7  1  2  1\n",
      "  0  1  8  3  3  6 10  2  2  5  3  8  2  2  7  7  7  7  4  4  2  4  8  3\n",
      "  3  1  2  2  6  1  7  7  6  3  7  1  6  5  4  6  2 10  7  5  3  2  3  9\n",
      "  4  1  7 10  7  6  8  1  4  9  5  6  2  1  1  2  1  5  4  7  2  9  3  1\n",
      "  0  3  2  2  8  4  4  4  5  1  2  8  1  7  8  7  2  1  3  6  3  1  2  5\n",
      "  2  1  7  3  1  1  1  3  7  6  2  3  1  9  2  7  7  5  1 10  3  2  2  3\n",
      "  3  9  7  2  8  8  1 10  2  3  3  3  2  3  3  5  5 10  1  6  2  3  9  7\n",
      "  7  1  1  8  2  2  3  2  7  7 10  1  0  1  9  1  4  1  8  4  5 10  1  2\n",
      " 10  7  0  7  5  9  8  5  1  3  6  2  2  8  2  7  2  1  1  1  3  4 10  7\n",
      "  2  1  1  3  1  2  1  3  5  6  7  3  6  7  2  5  2  0  7  4  1  7  2  7\n",
      "  5 10  2  1  9  4  9  7  2  2  9  5  2  8 10  3  2  6  3  1  1  9  4  6\n",
      "  9  2  1  7  3  2  1  6  9  1  1  2  2  9  0  3 10  3  1  2  7  2  7  9\n",
      "  4  6  2  7  7  1  7  9  6  1  2  8  1  2 10 10  8  8  9  7  1  5  6  3\n",
      "  2  7  4  2  6  6  8  3  3  7  7  1  5  7 10 10  0  9  7 10  1  4 10  7\n",
      "  1  1  1  5  1  1  1  1  6  3  7  1  4  4  4  3  2  7  1  5  5  0  1  1\n",
      "  2  3  1  3  5  7  7  8  6  2  1  3  2  2  5 10  1  7  2  1  1 10  6  2\n",
      "  8  7  1  6 10  5  7  4 10  1  2  7  9  7  8  4  0  7  1  5  7  7  2  1\n",
      "  4  1  1  3  1  1 10  1 10  7 10  1  1  2  1  1  5  7  3  1  1  2  2  9\n",
      "  2  6  5  1  1  2  5  4  2  2  3  7  3  5  9  8  1  2  2  1  6  7  9  5\n",
      "  9 10  2  3  2  1  8  4  3  1  5  5 10  2 10  8  9  2  4  6  3  3 10  1\n",
      "  1  6  3  8  4  7 10  2  4  7  7  7  3  2  2  4  4  3  3  6  0  1  4 10\n",
      "  9 10  1  5 10  1  7  3  4  5  4  4  1  1  1  3  2  3  1  0 10  2  1 10\n",
      "  9  3  4  2  4  1  5  2  1  5  5  3  1  7  4  4  7  4  2  1  7  1  2  9\n",
      "  5  6  9  5  0  3  1  9  2  7  4 10  3  5  4  4  1  7  7  6  1 10  5  1\n",
      "  2  4  4  8  7  1  3  4  2  3 10  7 10  5  3  1  1 10  7  3  3  7  4  5\n",
      "  3  8  5  8  7  9  8  8  6  6  2  4  5  1  8  5  2  1  8  4  7  7  4  5\n",
      "  4  2  4  6  2  2  2  1  6  6  4  1  2  4  5  1  7  3  5 10  1  4  7  7\n",
      " 10  2  7  7  2  1  0  2  8  4  1  2  6  4  0  5  7  1  1 10  1  7  4  1\n",
      "  8  8  4  1  1  7  2  1  8  5  7  8  1 10 10 10  2  1  8  1  1  7  4  6\n",
      "  2  5  7  7  3 10  1  6  4  2  1  3  1  4  2  6  8  1 10  2  5  2  7  1\n",
      "  2  3  5  2  2  8  7  8  3  9  3 10  7  1  1  4  1  5  7  3  4 10 10  1\n",
      "  2  2  3  1  1  2  1  7  1  3  6  7  5  4  2  2  1  4 10  1  3  2 10  7\n",
      "  3  7  4 10  2  1  7  4  2  5  1  2  1  1  0 10  4  1  3  6 10  2  6  7\n",
      " 10 10  7  6  7  8  2  9  0 10  5 10 10  5  2  3  3  1  0 10  9  1  0  3\n",
      "  8  1  9  5  1  3  7  3 10  1  6 10  4  2 10  4  1  4  7  3  0  5  3  4\n",
      "  1  1  1  2  2  7  6  2  7 10  5  9  4  2  4  6  1  2  1  8  1 10  3 10\n",
      "  2  0  4  4  7  8  7  4  5  2  1  8  9  2  2  5  1  7  4 10  3  5  1  1\n",
      "  4  7 10  0 10  5 10  5  1  8  1  7  1  0  2  7  6  7  8  2  3  7  1  1\n",
      "  1  8  2  1  5  4  8  6  4 10  1  2  3  7  7  2  1  3  6  6  1  8  3  1\n",
      "  2  4  1  4  5  2 10  7  2  2  6  4  6  2  2 10  3  0 10  1  3  2  7  2\n",
      "  2  1  3  1  2  4  5  3  2  8  2  4  4  3  1  8  1  8  2  1  4  3  7  1\n",
      "  2  0  2  7  5  7  1  1  7  1  3  1  9  4  4  7  3  1  7  4  1  7  7  2\n",
      "  8  7  0  1  1  7  3  9  4  4  2  2  1  1  2 10  6  6  5  2  3 10  1  3\n",
      "  9  8  7 10 10  7  1  3 10  2  1  3  2  1  5  1  4  1 10  7  4  2  2  1\n",
      "  1  1  4  5  1  3  1  4  6  3  5  2  9  3  8  2  4  8  4  1  1  2  4  7\n",
      "  5  7  1  5  0  1  1  3 10  3  7  8  2  5  7  4  7  3  1  1  2  5  9  3\n",
      "  3 10  2  1  7  5  1  1  3  5  4  1  8  6  3 10 10  4  1  7  6  4  3  2\n",
      "  2  6  8  7  2  1  0  3  4  8  1  3  6  5  2  3 10  3  1  0  2  6  7  7\n",
      "  2  5  3  7 10  1  1  2  4  6  7  4  2  3  1 10  7  1  2  1  1  2  6  1\n",
      "  4  2  7  7  1  5  6  9  2  8  1  6  5  1  2  0 10  2  8 10  2  1  2 10\n",
      "  2  1  1 10  7  0  3  2  1  7  3  3  4  2  1  3  0  8  2  2  2  2  1  2\n",
      "  7 10  8  1 10  1  8 10  5  2  2  7  3  3  9  1  2  4 10  1 10  1  1  3\n",
      "  9  3  7  6  7  5  1 10 10  4  7  2 10  7  7  3  1  1  3 10  5  1  0  4\n",
      "  8  7  5  7  6  1  1  2  4  1  6  1]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "print(result.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score\n",
    "from matplotlib import cm\n",
    "\n",
    "def plotSilhouette(X, y_km):\n",
    "    cluster_labels = np.unique(y_km.labels_)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_score(X, y_km.labels_,metric='euclidean')\n",
    "    print(silhouette_vals)\n",
    "#     y_ax_lower, y_ax_upper = 0,0\n",
    "#     yticks = []\n",
    "    \n",
    "#     for i , c in enumerate(cluster_labels):\n",
    "#         c_silhouette_vals = silhouette_vals[y_km.labels_ == c]\n",
    "#         c_silhouette_vals.sort()\n",
    "#         y_ax_upper += len(c_silhouette_vals)\n",
    "#         color = cm.jet(i/n_clusters)\n",
    "        \n",
    "#         plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0,edgecolor='none', color=color)\n",
    "#         yticks.append((y_ax_lower + y_ax_upper)/2)\n",
    "#         y_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "#     silhouette_avg = np.mean(silhouette_vals)\n",
    "#     plt.axvline(silhouette_avg, color='red', linestyle='--')\n",
    "#     plt.yticks(yticks, cluster_labels+1)\n",
    "#     plt.ylabel('cluster')\n",
    "#     plt.xlabel('silhouette score')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1815878815175326\n"
     ]
    }
   ],
   "source": [
    "plotSilhouette(features,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"insect_16_0.19706.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
