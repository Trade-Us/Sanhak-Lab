{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f = open('resources/InsectWingbeatSound/InsectWingbeatSound_TEST','r')\n",
    "data = f.read()\n",
    "f.close()\n",
    "# 개행문자 기준으로 끊어서 리스트로\n",
    "data_list = data.split('\\n')\n",
    "\n",
    "# \",\" 기준으로 끊어서 리스트로\n",
    "emptylist = []\n",
    "for list_part in data_list:\n",
    "    emptylist.append(list_part.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str -> float 변환\n",
    "tofloat = []\n",
    "for partlist in emptylist:\n",
    "    tofloat.append([float(i) for i in partlist]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980,)\n",
      "(1980, 256)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "data_list = []\n",
    "for datas in tofloat:\n",
    "    labels.append(datas[0])\n",
    "    data_list.append(datas[1:])\n",
    "print(np.shape(labels))\n",
    "print(np.shape(data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readFile import split_into_values, toRPdata\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler\n",
    "\n",
    "def Standard(data):\n",
    "    SS = StandardScaler().fit(data)\n",
    "    scaled = SS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "def MinMax(data):\n",
    "    MMS = MinMaxScaler().fit(data)\n",
    "    scaled = MMS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "# result_list transpose\n",
    "result_T = [list(x) for x in zip(*data_list)]\n",
    "\n",
    "# minmax 정규화\n",
    "result_scaled = Standard(result_T)\n",
    "\n",
    "# 다시 result transpose 해서 원래대로\n",
    "result_scaled = [list(x) for x in zip(*result_scaled)]\n",
    "\n",
    "result_ = np.array(result_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256, 256, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = result_.reshape(result_.shape[0], 1, result_.shape[1])\n",
    "X = toRPdata(data, threshold='point', percentage=30)\n",
    "#X = toRPdata(data)\n",
    "    \n",
    "X_scaled = np.expand_dims(X, axis=3)\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1af39eb17b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-5\n",
    "optimizer='Adam'\n",
    "loss='mse'\n",
    "image_size = 256 #1024, 256\n",
    "dimension = 4 # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 128)     1280      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 1)           10        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 1)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 256, 1)       1153      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256, 256, 1)       0         \n",
      "=================================================================\n",
      "Total params: 187,660\n",
      "Trainable params: 187,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from utils import split_data, normalization_tool\n",
    "from agent import Autoencoder_Agent\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_data(X_scaled, X_scaled) #데이터 분리\n",
    "\n",
    "autoencoder = Autoencoder_Agent(model_size=image_size, dimension=dimension, optimizer=optimizer,learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6471\n",
      "Epoch 00001: val_loss improved from inf to 0.61510, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 25s 171ms/step - loss: 0.6471 - val_loss: 0.6151\n",
      "Epoch 2/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6075\n",
      "Epoch 00002: val_loss improved from 0.61510 to 0.60571, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.6075 - val_loss: 0.6057\n",
      "Epoch 3/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6039\n",
      "Epoch 00003: val_loss improved from 0.60571 to 0.60400, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.6039 - val_loss: 0.6040\n",
      "Epoch 4/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.602 - ETA: 0s - loss: 0.6022\n",
      "Epoch 00004: val_loss improved from 0.60400 to 0.60271, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.6022 - val_loss: 0.6027\n",
      "Epoch 5/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6007\n",
      "Epoch 00005: val_loss improved from 0.60271 to 0.60161, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.6007 - val_loss: 0.6016\n",
      "Epoch 6/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5997\n",
      "Epoch 00006: val_loss improved from 0.60161 to 0.60092, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5997 - val_loss: 0.6009\n",
      "Epoch 7/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5990\n",
      "Epoch 00007: val_loss improved from 0.60092 to 0.60047, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5990 - val_loss: 0.6005\n",
      "Epoch 8/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5984\n",
      "Epoch 00008: val_loss improved from 0.60047 to 0.59997, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5984 - val_loss: 0.6000\n",
      "Epoch 9/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5980\n",
      "Epoch 00009: val_loss improved from 0.59997 to 0.59956, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5980 - val_loss: 0.5996\n",
      "Epoch 10/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5975\n",
      "Epoch 00010: val_loss improved from 0.59956 to 0.59939, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5975 - val_loss: 0.5994\n",
      "Epoch 11/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5972\n",
      "Epoch 00011: val_loss improved from 0.59939 to 0.59893, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5972 - val_loss: 0.5989\n",
      "Epoch 12/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5968\n",
      "Epoch 00012: val_loss improved from 0.59893 to 0.59889, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5968 - val_loss: 0.5989\n",
      "Epoch 13/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5964\n",
      "Epoch 00013: val_loss improved from 0.59889 to 0.59843, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5964 - val_loss: 0.5984\n",
      "Epoch 14/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5960\n",
      "Epoch 00014: val_loss improved from 0.59843 to 0.59796, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5960 - val_loss: 0.5980\n",
      "Epoch 15/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5954\n",
      "Epoch 00015: val_loss improved from 0.59796 to 0.59692, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5954 - val_loss: 0.5969\n",
      "Epoch 16/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5902\n",
      "Epoch 00016: val_loss improved from 0.59692 to 0.58901, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5902 - val_loss: 0.5890\n",
      "Epoch 17/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5856\n",
      "Epoch 00017: val_loss improved from 0.58901 to 0.58722, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5856 - val_loss: 0.5872\n",
      "Epoch 18/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5841\n",
      "Epoch 00018: val_loss improved from 0.58722 to 0.58683, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5841 - val_loss: 0.5868\n",
      "Epoch 19/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5834\n",
      "Epoch 00019: val_loss improved from 0.58683 to 0.58654, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5834 - val_loss: 0.5865\n",
      "Epoch 20/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5830\n",
      "Epoch 00020: val_loss improved from 0.58654 to 0.58630, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5830 - val_loss: 0.5863\n",
      "Epoch 21/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5827\n",
      "Epoch 00021: val_loss did not improve from 0.58630\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5827 - val_loss: 0.5867\n",
      "Epoch 22/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5824\n",
      "Epoch 00022: val_loss improved from 0.58630 to 0.58611, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5824 - val_loss: 0.5861\n",
      "Epoch 23/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5822\n",
      "Epoch 00023: val_loss improved from 0.58611 to 0.58569, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5822 - val_loss: 0.5857\n",
      "Epoch 24/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5820\n",
      "Epoch 00024: val_loss improved from 0.58569 to 0.58553, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5820 - val_loss: 0.5855\n",
      "Epoch 25/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5818\n",
      "Epoch 00025: val_loss did not improve from 0.58553\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5818 - val_loss: 0.5863\n",
      "Epoch 26/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5816\n",
      "Epoch 00026: val_loss improved from 0.58553 to 0.58542, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5816 - val_loss: 0.5854\n",
      "Epoch 27/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5813\n",
      "Epoch 00027: val_loss improved from 0.58542 to 0.58517, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5813 - val_loss: 0.5852\n",
      "Epoch 28/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5811\n",
      "Epoch 00028: val_loss improved from 0.58517 to 0.58515, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5811 - val_loss: 0.5851\n",
      "Epoch 29/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5809\n",
      "Epoch 00029: val_loss improved from 0.58515 to 0.58488, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5809 - val_loss: 0.5849\n",
      "Epoch 30/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5808\n",
      "Epoch 00030: val_loss did not improve from 0.58488\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5808 - val_loss: 0.5852\n",
      "Epoch 31/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5806\n",
      "Epoch 00031: val_loss did not improve from 0.58488\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5806 - val_loss: 0.5852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5804\n",
      "Epoch 00032: val_loss did not improve from 0.58488\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5804 - val_loss: 0.5850\n",
      "Epoch 33/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5804\n",
      "Epoch 00033: val_loss improved from 0.58488 to 0.58475, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5804 - val_loss: 0.5848\n",
      "Epoch 34/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5801\n",
      "Epoch 00034: val_loss did not improve from 0.58475\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5801 - val_loss: 0.5852\n",
      "Epoch 35/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5799\n",
      "Epoch 00035: val_loss did not improve from 0.58475\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5799 - val_loss: 0.5852\n",
      "Epoch 36/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5799\n",
      "Epoch 00036: val_loss did not improve from 0.58475\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5799 - val_loss: 0.5849\n",
      "Epoch 37/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5797\n",
      "Epoch 00037: val_loss improved from 0.58475 to 0.58446, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5797 - val_loss: 0.5845\n",
      "Epoch 38/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5795\n",
      "Epoch 00038: val_loss did not improve from 0.58446\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5795 - val_loss: 0.5851\n",
      "Epoch 39/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5794\n",
      "Epoch 00039: val_loss did not improve from 0.58446\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5794 - val_loss: 0.5848\n",
      "Epoch 40/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5794\n",
      "Epoch 00040: val_loss improved from 0.58446 to 0.58431, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5794 - val_loss: 0.5843\n",
      "Epoch 41/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5792\n",
      "Epoch 00041: val_loss did not improve from 0.58431\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5792 - val_loss: 0.5845\n",
      "Epoch 42/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5789\n",
      "Epoch 00042: val_loss did not improve from 0.58431\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5789 - val_loss: 0.5845\n",
      "Epoch 43/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5789\n",
      "Epoch 00043: val_loss did not improve from 0.58431\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5789 - val_loss: 0.5844\n",
      "Epoch 44/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5789\n",
      "Epoch 00044: val_loss did not improve from 0.58431\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5789 - val_loss: 0.5843\n",
      "Epoch 45/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5786\n",
      "Epoch 00045: val_loss improved from 0.58431 to 0.58411, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5786 - val_loss: 0.5841\n",
      "Epoch 46/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5786\n",
      "Epoch 00046: val_loss did not improve from 0.58411\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5786 - val_loss: 0.5847\n",
      "Epoch 47/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5785\n",
      "Epoch 00047: val_loss improved from 0.58411 to 0.58402, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5785 - val_loss: 0.5840\n",
      "Epoch 48/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5783\n",
      "Epoch 00048: val_loss improved from 0.58402 to 0.58383, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5783 - val_loss: 0.5838\n",
      "Epoch 49/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5782\n",
      "Epoch 00049: val_loss did not improve from 0.58383\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5782 - val_loss: 0.5842\n",
      "Epoch 50/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5781\n",
      "Epoch 00050: val_loss did not improve from 0.58383\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5781 - val_loss: 0.5841\n",
      "Epoch 51/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5779\n",
      "Epoch 00051: val_loss did not improve from 0.58383\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5779 - val_loss: 0.5843\n",
      "Epoch 52/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5779\n",
      "Epoch 00052: val_loss did not improve from 0.58383\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5779 - val_loss: 0.5840\n",
      "Epoch 53/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5777\n",
      "Epoch 00053: val_loss did not improve from 0.58383\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5777 - val_loss: 0.5840\n",
      "Epoch 54/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5777\n",
      "Epoch 00054: val_loss did not improve from 0.58383\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5777 - val_loss: 0.5840\n",
      "Epoch 55/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5775\n",
      "Epoch 00055: val_loss did not improve from 0.58383\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5775 - val_loss: 0.5839\n",
      "Epoch 56/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5774\n",
      "Epoch 00056: val_loss did not improve from 0.58383\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5774 - val_loss: 0.5839\n",
      "Epoch 57/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5774\n",
      "Epoch 00057: val_loss did not improve from 0.58383\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5774 - val_loss: 0.5846\n",
      "Epoch 58/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5772\n",
      "Epoch 00058: val_loss improved from 0.58383 to 0.58375, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5772 - val_loss: 0.5837\n",
      "Epoch 59/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5771\n",
      "Epoch 00059: val_loss improved from 0.58375 to 0.58369, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5771 - val_loss: 0.5837\n",
      "Epoch 60/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5771\n",
      "Epoch 00060: val_loss did not improve from 0.58369\n",
      "149/149 [==============================] - 25s 167ms/step - loss: 0.5771 - val_loss: 0.5839\n",
      "Epoch 61/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5770\n",
      "Epoch 00061: val_loss did not improve from 0.58369\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5770 - val_loss: 0.5837\n",
      "Epoch 62/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5769\n",
      "Epoch 00062: val_loss improved from 0.58369 to 0.58355, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5769 - val_loss: 0.5836\n",
      "Epoch 63/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5767\n",
      "Epoch 00063: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5767 - val_loss: 0.5839\n",
      "Epoch 64/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5767\n",
      "Epoch 00064: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.5767 - val_loss: 0.5837\n",
      "Epoch 65/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5766\n",
      "Epoch 00065: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5766 - val_loss: 0.5839\n",
      "Epoch 66/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5764\n",
      "Epoch 00066: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5764 - val_loss: 0.5840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5764\n",
      "Epoch 00067: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5764 - val_loss: 0.5838\n",
      "Epoch 68/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5763\n",
      "Epoch 00068: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5763 - val_loss: 0.5839\n",
      "Epoch 69/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5762\n",
      "Epoch 00069: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5762 - val_loss: 0.5840\n",
      "Epoch 70/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5761\n",
      "Epoch 00070: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5761 - val_loss: 0.5839\n",
      "Epoch 71/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5760\n",
      "Epoch 00071: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5760 - val_loss: 0.5844\n",
      "Epoch 72/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5760\n",
      "Epoch 00072: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5760 - val_loss: 0.5839\n",
      "Epoch 73/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5760\n",
      "Epoch 00073: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5760 - val_loss: 0.5836\n",
      "Epoch 74/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5758\n",
      "Epoch 00074: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5758 - val_loss: 0.5840\n",
      "Epoch 75/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5757\n",
      "Epoch 00075: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5757 - val_loss: 0.5837\n",
      "Epoch 76/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5756\n",
      "Epoch 00076: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5756 - val_loss: 0.5837\n",
      "Epoch 77/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5756\n",
      "Epoch 00077: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5756 - val_loss: 0.5836\n",
      "Epoch 78/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5755\n",
      "Epoch 00078: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5755 - val_loss: 0.5840\n",
      "Epoch 79/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5754\n",
      "Epoch 00079: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5754 - val_loss: 0.5838\n",
      "Epoch 80/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5753\n",
      "Epoch 00080: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5753 - val_loss: 0.5841\n",
      "Epoch 81/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5752\n",
      "Epoch 00081: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5752 - val_loss: 0.5837\n",
      "Epoch 82/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5752\n",
      "Epoch 00082: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5752 - val_loss: 0.5840\n",
      "Epoch 83/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5750\n",
      "Epoch 00083: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5750 - val_loss: 0.5842\n",
      "Epoch 84/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5751\n",
      "Epoch 00084: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5751 - val_loss: 0.5836\n",
      "Epoch 85/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5749\n",
      "Epoch 00085: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5749 - val_loss: 0.5840\n",
      "Epoch 86/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5749\n",
      "Epoch 00086: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5749 - val_loss: 0.5841\n",
      "Epoch 87/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5747\n",
      "Epoch 00087: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5747 - val_loss: 0.5843\n",
      "Epoch 88/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5748\n",
      "Epoch 00088: val_loss did not improve from 0.58355\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5748 - val_loss: 0.5837\n",
      "Epoch 89/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5747\n",
      "Epoch 00089: val_loss improved from 0.58355 to 0.58345, saving model to insectWing_dimension_4.h5\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5747 - val_loss: 0.5834\n",
      "Epoch 90/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5746\n",
      "Epoch 00090: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5746 - val_loss: 0.5846\n",
      "Epoch 91/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5745\n",
      "Epoch 00091: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5745 - val_loss: 0.5843\n",
      "Epoch 92/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5745\n",
      "Epoch 00092: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5745 - val_loss: 0.5839\n",
      "Epoch 93/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5743\n",
      "Epoch 00093: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5743 - val_loss: 0.5839\n",
      "Epoch 94/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5742\n",
      "Epoch 00094: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5742 - val_loss: 0.5844\n",
      "Epoch 95/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5742\n",
      "Epoch 00095: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5742 - val_loss: 0.5841\n",
      "Epoch 96/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5742\n",
      "Epoch 00096: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5742 - val_loss: 0.5839\n",
      "Epoch 97/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5740\n",
      "Epoch 00097: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5740 - val_loss: 0.5838\n",
      "Epoch 98/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5739\n",
      "Epoch 00098: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5739 - val_loss: 0.5841\n",
      "Epoch 99/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5740\n",
      "Epoch 00099: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5740 - val_loss: 0.5837\n",
      "Epoch 100/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5738\n",
      "Epoch 00100: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5738 - val_loss: 0.5840\n",
      "Epoch 101/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5739\n",
      "Epoch 00101: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5739 - val_loss: 0.5845\n",
      "Epoch 102/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5738\n",
      "Epoch 00102: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5738 - val_loss: 0.5838\n",
      "Epoch 103/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5737\n",
      "Epoch 00103: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5737 - val_loss: 0.5839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5737\n",
      "Epoch 00104: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5737 - val_loss: 0.5838\n",
      "Epoch 105/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5737\n",
      "Epoch 00105: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5737 - val_loss: 0.5841\n",
      "Epoch 106/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5735\n",
      "Epoch 00106: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5735 - val_loss: 0.5842\n",
      "Epoch 107/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5736\n",
      "Epoch 00107: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5736 - val_loss: 0.5838\n",
      "Epoch 108/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5735\n",
      "Epoch 00108: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5735 - val_loss: 0.5840\n",
      "Epoch 109/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5734\n",
      "Epoch 00109: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5734 - val_loss: 0.5839\n",
      "Epoch 110/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5733\n",
      "Epoch 00110: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5733 - val_loss: 0.5851\n",
      "Epoch 111/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5733\n",
      "Epoch 00111: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5733 - val_loss: 0.5840\n",
      "Epoch 112/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5732\n",
      "Epoch 00112: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5732 - val_loss: 0.5841\n",
      "Epoch 113/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5732\n",
      "Epoch 00113: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5732 - val_loss: 0.5837\n",
      "Epoch 114/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5731\n",
      "Epoch 00114: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5731 - val_loss: 0.5836\n",
      "Epoch 115/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5729\n",
      "Epoch 00115: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5729 - val_loss: 0.5842\n",
      "Epoch 116/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5730\n",
      "Epoch 00116: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5730 - val_loss: 0.5846\n",
      "Epoch 117/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5729\n",
      "Epoch 00117: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5729 - val_loss: 0.5841\n",
      "Epoch 118/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5730\n",
      "Epoch 00118: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5730 - val_loss: 0.5838\n",
      "Epoch 119/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5728\n",
      "Epoch 00119: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5728 - val_loss: 0.5850\n",
      "Epoch 120/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5728\n",
      "Epoch 00120: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5728 - val_loss: 0.5841\n",
      "Epoch 121/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5728\n",
      "Epoch 00121: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5728 - val_loss: 0.5857\n",
      "Epoch 122/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5728\n",
      "Epoch 00122: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5728 - val_loss: 0.5839\n",
      "Epoch 123/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5728\n",
      "Epoch 00123: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5728 - val_loss: 0.5843\n",
      "Epoch 124/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5727\n",
      "Epoch 00124: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5727 - val_loss: 0.5840\n",
      "Epoch 125/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5726\n",
      "Epoch 00125: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5726 - val_loss: 0.5842\n",
      "Epoch 126/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5725\n",
      "Epoch 00126: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5725 - val_loss: 0.5841\n",
      "Epoch 127/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5724\n",
      "Epoch 00127: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5724 - val_loss: 0.5841\n",
      "Epoch 128/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5725\n",
      "Epoch 00128: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5725 - val_loss: 0.5844\n",
      "Epoch 129/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5725\n",
      "Epoch 00129: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5725 - val_loss: 0.5846\n",
      "Epoch 130/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5724\n",
      "Epoch 00130: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5724 - val_loss: 0.5840\n",
      "Epoch 131/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5723\n",
      "Epoch 00131: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5723 - val_loss: 0.5840\n",
      "Epoch 132/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5724\n",
      "Epoch 00132: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5724 - val_loss: 0.5839\n",
      "Epoch 133/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5723\n",
      "Epoch 00133: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5723 - val_loss: 0.5839\n",
      "Epoch 134/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5721\n",
      "Epoch 00134: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5721 - val_loss: 0.5840\n",
      "Epoch 135/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5721\n",
      "Epoch 00135: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5721 - val_loss: 0.5845\n",
      "Epoch 136/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5722\n",
      "Epoch 00136: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5722 - val_loss: 0.5839\n",
      "Epoch 137/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5721\n",
      "Epoch 00137: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5721 - val_loss: 0.5843\n",
      "Epoch 138/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5722\n",
      "Epoch 00138: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5722 - val_loss: 0.5840\n",
      "Epoch 139/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5721\n",
      "Epoch 00139: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5721 - val_loss: 0.5844\n",
      "Epoch 140/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5720\n",
      "Epoch 00140: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5720 - val_loss: 0.5841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5719\n",
      "Epoch 00141: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5719 - val_loss: 0.5842\n",
      "Epoch 142/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5719\n",
      "Epoch 00142: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5719 - val_loss: 0.5839\n",
      "Epoch 143/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5718\n",
      "Epoch 00143: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5718 - val_loss: 0.5843\n",
      "Epoch 144/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5718\n",
      "Epoch 00144: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5718 - val_loss: 0.5843\n",
      "Epoch 145/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5717\n",
      "Epoch 00145: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5717 - val_loss: 0.5842\n",
      "Epoch 146/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5716\n",
      "Epoch 00146: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5716 - val_loss: 0.5845\n",
      "Epoch 147/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5716\n",
      "Epoch 00147: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5716 - val_loss: 0.5844\n",
      "Epoch 148/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5717\n",
      "Epoch 00148: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5717 - val_loss: 0.5841\n",
      "Epoch 149/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5715\n",
      "Epoch 00149: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5715 - val_loss: 0.5845\n",
      "Epoch 150/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5716\n",
      "Epoch 00150: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5716 - val_loss: 0.5841\n",
      "Epoch 151/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5715\n",
      "Epoch 00151: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5715 - val_loss: 0.5850\n",
      "Epoch 152/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5715\n",
      "Epoch 00152: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5715 - val_loss: 0.5845\n",
      "Epoch 153/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5716\n",
      "Epoch 00153: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5716 - val_loss: 0.5841\n",
      "Epoch 154/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5714\n",
      "Epoch 00154: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5714 - val_loss: 0.5842\n",
      "Epoch 155/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5714\n",
      "Epoch 00155: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5714 - val_loss: 0.5855\n",
      "Epoch 156/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5715\n",
      "Epoch 00156: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5715 - val_loss: 0.5846\n",
      "Epoch 157/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5713\n",
      "Epoch 00157: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5713 - val_loss: 0.5850\n",
      "Epoch 158/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5714\n",
      "Epoch 00158: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 164ms/step - loss: 0.5714 - val_loss: 0.5842\n",
      "Epoch 159/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5712\n",
      "Epoch 00159: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5712 - val_loss: 0.5850\n",
      "Epoch 160/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5712\n",
      "Epoch 00160: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5712 - val_loss: 0.5845\n",
      "Epoch 161/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5712\n",
      "Epoch 00161: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5712 - val_loss: 0.5851\n",
      "Epoch 162/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5713\n",
      "Epoch 00162: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5713 - val_loss: 0.5844\n",
      "Epoch 163/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5712\n",
      "Epoch 00163: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5712 - val_loss: 0.5846\n",
      "Epoch 164/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5710\n",
      "Epoch 00164: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5710 - val_loss: 0.5850\n",
      "Epoch 165/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5710\n",
      "Epoch 00165: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5710 - val_loss: 0.5847\n",
      "Epoch 166/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5710\n",
      "Epoch 00166: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5710 - val_loss: 0.5852\n",
      "Epoch 167/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5709\n",
      "Epoch 00167: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5709 - val_loss: 0.5842\n",
      "Epoch 168/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5709\n",
      "Epoch 00168: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5709 - val_loss: 0.5848\n",
      "Epoch 169/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5708\n",
      "Epoch 00169: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5708 - val_loss: 0.5848\n",
      "Epoch 170/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5709\n",
      "Epoch 00170: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5709 - val_loss: 0.5847\n",
      "Epoch 171/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5709\n",
      "Epoch 00171: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5709 - val_loss: 0.5846\n",
      "Epoch 172/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5708\n",
      "Epoch 00172: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5708 - val_loss: 0.5850\n",
      "Epoch 173/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5708\n",
      "Epoch 00173: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5708 - val_loss: 0.5846\n",
      "Epoch 174/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5709\n",
      "Epoch 00174: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5709 - val_loss: 0.5847\n",
      "Epoch 175/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5708\n",
      "Epoch 00175: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5708 - val_loss: 0.5849\n",
      "Epoch 176/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5707\n",
      "Epoch 00176: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.5707 - val_loss: 0.5851\n",
      "Epoch 177/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5707\n",
      "Epoch 00177: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 25s 166ms/step - loss: 0.5707 - val_loss: 0.5849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5706\n",
      "Epoch 00178: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.5706 - val_loss: 0.5848\n",
      "Epoch 179/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5705\n",
      "Epoch 00179: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5705 - val_loss: 0.5852\n",
      "Epoch 180/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5705\n",
      "Epoch 00180: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5705 - val_loss: 0.5851\n",
      "Epoch 181/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5706\n",
      "Epoch 00181: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5706 - val_loss: 0.5862\n",
      "Epoch 182/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5704\n",
      "Epoch 00182: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5704 - val_loss: 0.5848\n",
      "Epoch 183/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5705\n",
      "Epoch 00183: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5705 - val_loss: 0.5852\n",
      "Epoch 184/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5704\n",
      "Epoch 00184: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5704 - val_loss: 0.5849\n",
      "Epoch 185/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5704\n",
      "Epoch 00185: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5704 - val_loss: 0.5853\n",
      "Epoch 186/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5704\n",
      "Epoch 00186: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5704 - val_loss: 0.5849\n",
      "Epoch 187/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5704\n",
      "Epoch 00187: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5704 - val_loss: 0.5852\n",
      "Epoch 188/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5703\n",
      "Epoch 00188: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5703 - val_loss: 0.5849\n",
      "Epoch 189/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5702\n",
      "Epoch 00189: val_loss did not improve from 0.58345\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.5702 - val_loss: 0.5855\n",
      "Epoch 00189: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.train(X_train,batch_size,epochs,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "# loss_ax.plot([hist['loss'][i] - hist['val_loss'][i] for i in range(len(hist['loss']))], 'g', label='loss - val loss')\n",
    "\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 4)\n"
     ]
    }
   ],
   "source": [
    "features = np.empty((0,4), float)\n",
    "for i in range(66):\n",
    "    features = np.append(features, autoencoder.feature_extract(X_scaled[i*30:(i+1)*30]), axis=0)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22645597064637907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "result = KMeans(n_clusters=11).fit(features)\n",
    "plotSilhouette(features,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  4  0  0  2  0  5  4  9  6  7  9  2  5  4  4  4  0  9 10  5  2 10 10\n",
      "  4  6  4  5  5  6  4  6  0  6  6  6  8  5  0  5  3  4  8  0  4  6  0  4\n",
      "  4  2  0  0  5  3 10  4  6  6  4  0  2  6  4  7  4  3  8  6  3  0  7  3\n",
      "  6  7  4  6  8  9  0 10  4 10  4  6  0  7  4  4  5  6  2  4  4  2  0  5\n",
      "  0  7  0  3  4  0  7  7  4  6  0  0  4  5  0  2  8  6  6  4  6  3  8  4\n",
      "  6  6  3  2  7  0  0  7  0  4  7  4  1  5  3  0  6  7  5  6  3  4  6  7\n",
      "  5  2  4  8  0  0  4  4  4  6  3  0 10  4  5  0  4  4  0  7  4  6  9 10\n",
      "  3  7  2  7  0  6  4  4  0  5  1 10  4  4  6  5  4  8  2  5  3  5  5  4\n",
      "  3  0  5  6  2  2  5  8  0 10  4  7  4  3  2  6  4  4  5  1  5  5  0 10\n",
      "  7  4  0  4  5  6  3  1  4  5 10  7  4  1  9  9  4  7  2  2  4  2  5 10\n",
      "  0  6  0  8  3  7  5  7  4  4  5  4  0  2  4  7  5  4  2  0  1  5  2  7\n",
      "  7  9  4  3  4  6  8  1  4  2  7  5  0  0 10  4  5  4  4  4  4  4  0  5\n",
      "  3 10  4  5  4  6  4  5  4  4  4  0  4  4  9 10  4  3  0  0  0  5  4  6\n",
      "  0  7  4  4  6  6  4  4  4  4  2  4  3  3  7  3  6  5  6  1  4  9  6  0\n",
      "  7  5  0  2  6  0  4  6 10  6  6  2  7  7  7  0 10  6  6  7  2  6  0  4\n",
      "  0  6  1  4  4 10  4  2  7  4  4  5  5  2  5  1  4  2  4  6  4  3  6  2\n",
      "  6  2  4  4  9  4  2  2  5  6  7  3  7  7  0  5  0  7  4  4  5  0  2  6\n",
      "  6  4  8  2  0  6  7  7  3  3 10  0  6  5  4  0  4  7 10  3  9  5  4  7\n",
      "  5  0  0  5  0  0 10  7  2  4 10  2  9  7  5  3  0  7  4  5  5  2  6  0\n",
      "  4  4  9  4  4 10  7  2  2  4 10  6  2  0  7  5  3  5  4  9  0  7  5  5\n",
      "  6  4  0  5 10  0  2 10  6  0  6  3  6  1  6  1  7  5  7  3  6  6  1  6\n",
      "  5  9  3  4  5  6  8  4  6  4  2  0  4  0  4  5  1  7  7  3  7  6  4  4\n",
      "  4  6  6  5  4  4  4  5  5 10 10  6  4  9  4  2  9  5  0  7  4  7  4  4\n",
      "  6  5  5  9  6  4  6  4  7  4  5  6  4  9  7  6  5  4  2  4  0  2  8  5\n",
      " 10  4  4  4  4  0  7  4  7  2  2  6  7  3  5  4 10  4  5  5  0  0  4  3\n",
      "  5  6  4  6 10  5  5  2  0  4  7  4 10  2  2  6  2  2  6  2  4  0  6  6\n",
      "  2  7  2  0  6  4  0  4  4  7  0  0  0  3  4  4  6  0  0  6  4  5  6  9\n",
      "  0  9  2  7  0  5  8  5  5  9  0  4  0  8  2  6  7  0  6  4  2  3  7  7\n",
      "  2  4  0  4  0  2  4  6  0  7  6  4  5  5  8  9  0  6  6  1  2  8  4  7\n",
      "  0  3  3  5  6 10  3  2  5  4  6  9  0  2  6  8  4  6  6  4  4  5  0  0\n",
      "  3  4  2  4  6  5  6  2  7 10  6  3  5  6  6  6  4  0  2  9  7  5  3  5\n",
      "  0  4  5  0 10  4  0  4 10  2  4  0 10  9  1  5  7  5  4  5  6  2  6  9\n",
      "  2  0  4  6  5  5  3  0  7  3  2  5  0  2  0  2  7  3 10  4  9  1  2  5\n",
      "  3  6  2  5  9  2  5  2 10  5  2  3  6  0  3  4  0  4  5  7  6  4  2  7\n",
      "  5  4  4  5  0  4  4  6  4  3  0  2  4 10  7  4  2  5  0  2  2  0  0  5\n",
      "  5  3  0  7  3  8  4  6  0  2  5  6  2  0  5  7 10  6  6  5  0  5 10  4\n",
      "  5  5  0  0  5  2  6  6  4  4  6  0  3  0  1  4  2  2 10  3 10  6  6  7\n",
      "  6  6  8  0  1  1  1  7  0  5  7  7  9  3  5  4  5  2  4  2  2  4  6  4\n",
      "  4  0  4  2  4  2  4  2 10  9  4  2  7  4  6  7  7  3  2  3  4  4  1  0\n",
      "  3  0  5  4  3  5  7  0  0 10 10  5 10  3  4  6  5  5  2  4  6  3 10 10\n",
      "  1  6  0  6  2  0  4  7 10  6  0  2  7 10 10  2  4  6  0  0  4  7  4  7\n",
      " 10  3  0  6  4  4  6  7  2  4  0  8  4  5  6  6  5  3  1  4 10  7  2  4\n",
      "  0  4  7  0  5  7  9  5  6  7  0  4  5  4  0  6  3  9  4  4  2  7  5  4\n",
      "  4  0  0  1  0  0  6  4  7  2  4  2  3  7 10  5  2  4  7  5 10  3  6 10\n",
      "  6  6  7  5 10  5  4  3  3  0  4  6  0  2  7  5  4  4  7  0  2  4  3  2\n",
      "  8  4  0  3  6 10  4  9  6  6  7  0  7  2  8  7  9  0  4 10  4  4  0  0\n",
      "  2  0  2  5  4  0  6  0  7  4  4  0  4  2  0  4  7  4  5  0  6  5  2 10\n",
      "  4  9 10  0  4  5 10  3  7  5  0  4  5  7  1  8  4  5  2  4 10  0  1 10\n",
      "  3  5  9  6  5  4 10  2  6  0  5  5  6  5  5  9  1  5  4  1  5  5  6  0\n",
      "  0  0  5  5  7  4  4  2 10  5  0  4  2 10  2  7  5  6  5  5  3  4  0  6\n",
      "  7  2  2  7  6  4  5  5  2  5 10  2  0  4  0  5  0  7  6  8  4  0  6  5\n",
      "  3  5  2  2  9  0  7  7  4 10 10  0  4  4  6  7  4  9  6  4  2  4  0  3\n",
      "  9  5  3  7  3  5  4  1  2  2  3  4  5  3  2  0  4  4  4  9  4  6  5  2\n",
      "  2  5  1  8  4  4  5  7  2  5  0  4  5  9  5  4  4  2  6  5 10  4  5 10\n",
      "  5  9  3  3  2 10  3  3 10 10  2  6  2  0 10 10  5  0  9  9  4  4  0  1\n",
      "  2  4  7 10  5  0  5  4 10  9  7  2  5  0 10  4  4  6  1  2  6  7  4  4\n",
      "  6  0 10  4  0  4  3  5  9  7  7  2 10  0  3  7  4  0  0  4  0  4  7  4\n",
      " 10  7  5  5  4  4  5  0  3 10  3  3  0  0  6  6  0  0  8  0  4  5  0  1\n",
      "  2  7  6  6  6  6  4  3  5  5  4  5  0  2  0  7  3  4  5  0  7  6  4  4\n",
      "  3  5  5  5  6  8  4  3  6  5  2  4  4  0  2  6  4 10  0  6  7  4  6  6\n",
      "  7  4  2  5  0  6  4  2  6  6  5  6  7 10  7  6  0  8  0  6  0  2  6  0\n",
      "  4  4  2  6  3  0  0  3  0  2  4  5  0  0  8  6  2  4  6 10  2  2  5  4\n",
      "  0  0  4 10  4 10  5  7  3  5 10  6  4  9  0  4  0  0 10  4  4  7  1  2\n",
      "  8  4  2 10  6  6  4  5  6  4  9  4  7  9  2  7  6  7  0  6  9  3  6  3\n",
      "  4  0  6  2  7  4  5  6  4  6  9  0  2  5  6  5  4  5  2  3  7  6  2  6\n",
      "  0  3  2  7  4  8  7  0  2  5  0  9  3  2  5 10  4  4  7  4  5 10  7  4\n",
      "  2  4  6  8  6  9  6 10  0  3  4  4  4  8  0  4  7  4  3 10  2  4  7  9\n",
      "  4  3  5  4  0  5  0 10  7  7  4  5  2  0  6  0  0  4  7  2  2  9  5  0\n",
      "  0  9  0  2 10  5  4  4  5  2  5  2  1  7  0  6  7  3  4  4  4  2  0  5\n",
      "  5  4  5  4  9  7  2  5  5  8  5  2 10  5  5  3  0  8  2  5  9  0  4  4\n",
      "  0  3  0  6  3  0  6  0  4  0  6  4  7  7  5  0  6  0  4 10  4  4  4  5\n",
      "  3  4  3  4  6  4  0 10  5  0  7  7  4  4  2  2  7  1  2  7  5  4  2  2\n",
      "  5  3  0  6  5  0  4  5  4  0  6  6 10  4  7  4  7  9  6  0  0  0  5  4\n",
      "  4  4  7  9  4  5  6  5  2  6  1  0  5  5  8  6 10  8 10  5  0  5  9  0\n",
      "  2  4  4  1  3  0  4  4  4  5  4  1 10  7  0 10  4  5  4  4  0 10  7  6\n",
      "  5  6  7  4  0  3  4  4  5  9  7  2  3 10  5  4  2  7  0  7  9  6 10 10\n",
      "  2  5  8  7  5  4  8  6  6  0  4  5  5 10  5  5  6  6  0  3  0  8  4  0\n",
      "  0  2  6  0  2  0  7  0  6 10  4  5  7  6  6  4  5  4  7  4  7  2  4  4\n",
      "  2  6  4  4  4  1 10  1  2  8  7  5  7  4  0  0  7  7  9  6  7  6  0  6\n",
      "  5  5  2  6  0 10  6  5 10  0  4  2  2  5  4  5  9  8  5  6  0  2  0  2\n",
      "  4  4 10  0  6  4  5  0  7  0  0  0  2  2  5  6  0  7  0  4  4  0  4  6\n",
      "  9  4  6  2  4  3  4  5  5 10  4  4  6  6  5  5  4  7  0  6 10  5  9  4\n",
      "  8  6 10  6  5  0  6  6  7  3  9  5]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "print(result.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score\n",
    "from matplotlib import cm\n",
    "\n",
    "def plotSilhouette(X, y_km):\n",
    "    cluster_labels = np.unique(y_km.labels_)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_score(X, y_km.labels_,metric='euclidean')\n",
    "    print(silhouette_vals)\n",
    "#     y_ax_lower, y_ax_upper = 0,0\n",
    "#     yticks = []\n",
    "    \n",
    "#     for i , c in enumerate(cluster_labels):\n",
    "#         c_silhouette_vals = silhouette_vals[y_km.labels_ == c]\n",
    "#         c_silhouette_vals.sort()\n",
    "#         y_ax_upper += len(c_silhouette_vals)\n",
    "#         color = cm.jet(i/n_clusters)\n",
    "        \n",
    "#         plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0,edgecolor='none', color=color)\n",
    "#         yticks.append((y_ax_lower + y_ax_upper)/2)\n",
    "#         y_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "#     silhouette_avg = np.mean(silhouette_vals)\n",
    "#     plt.axvline(silhouette_avg, color='red', linestyle='--')\n",
    "#     plt.yticks(yticks, cluster_labels+1)\n",
    "#     plt.ylabel('cluster')\n",
    "#     plt.xlabel('silhouette score')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2279039883123083\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"insect_128_8_mse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
