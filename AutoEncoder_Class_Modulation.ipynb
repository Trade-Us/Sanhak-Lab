{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Dense\n",
    "from keras.layers import Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "#from keras.preprocessing import image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_tool(data):\n",
    "    data_nor = data.astype('float32') / 255\n",
    "    \n",
    "    return data_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
    "    xy = (X_train, X_test, Y_train, Y_test)\n",
    "    np.save(\"./img_data.npy\", xy)\n",
    "    X_train, X_test, Y_train, Y_test = np.load('./img_data.npy', allow_pickle = True)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "epochs = 500\n",
    "\n",
    "optimizer='Adam'\n",
    "loss='binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_set(optimizer, learning_rate):\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = optimizers.SGD(lr=learning_rate, clipnorm=1.)\n",
    "        \n",
    "    if optimizer == 'RMSprop':\n",
    "        optimizer = optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)\n",
    "        \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        \n",
    "    if optimizer == 'Nadam':\n",
    "        optimizer = optimizers.Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "        \n",
    "    if optimizer == 'Adagrad':\n",
    "        optimizer = optimizers.Adagrad(lr=learning_rate, epsilon=None, decay=0.0)\n",
    "        \n",
    "    if optimizer == 'Adadelta':\n",
    "        optimizer = optimizers.Adadelta(lr=learning_rate, rho=0.95, epsilon=None, decay=0.0)\n",
    "        \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twentyeightCNNAutoEncoder():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1st convolution layer\n",
    "    model.add(Conv2D(16, (3, 3)  # 16 is number of filters and (3, 3) is the size of the filter.\n",
    "                 , padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    # 2nd convolution layer\n",
    "    model.add(Conv2D(2, (3, 3), padding='same'))  # apply 2 filters sized of (3x3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    # here compressed version\n",
    "\n",
    "    # 3rd convolution layer\n",
    "    model.add(Conv2D(2, (3, 3), padding='same'))  # apply 2 filters sized of (3x3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "    # 4rd convolution layer\n",
    "    model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(1, (3, 3), padding='same'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.save('./model/model.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ninetysixCNNAutoEncoder():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1st convolution layer\n",
    "    model.add(Conv2D(16, (3, 3)  # 16 is number of filters and (3, 3) is the size of the filter.\n",
    "                 , padding='same', input_shape=(96, 96, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    # 2nd convolution layer\n",
    "    model.add(Conv2D(2, (3, 3), padding='same'))  # apply 2 filters sized of (3x3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    # here compressed version\n",
    "\n",
    "    # 3rd convolution layer\n",
    "    model.add(Conv2D(2, (3, 3), padding='same'))  # apply 2 filters sized of (3x3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2), padding='same'))\n",
    "\n",
    "    # 4rd convolution layer\n",
    "    model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    \n",
    "    #5th convolution layer\n",
    "    model.add(Conv2D(2,(3, 3), padding='same')) # apply 2 filters sized of (3x3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    " \n",
    "    #6th convolution layer\n",
    "    model.add(Conv2D(16,(3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(1, (3, 3), padding='same'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.save('./model/model.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tool(X, Y, batch_size, learning_rate, epochs, optimizer, loss):\n",
    "    X_train, X_test, Y_train, Y_test = split_data(X, Y) #데이터 분리\n",
    "    X_train = normalization_tool(X_train) #데이터 정규화\n",
    "    X_test = normalization_tool(X_test) #데이터 정규화\n",
    "    \n",
    "    optimizer = optimizer_set(optimizer, learning_rate) #optimizer 설정\n",
    "    \n",
    "    model = model.load_model('./model/model.h5')\n",
    "    \n",
    "    #학습(약 7000번 정도 진행)\n",
    "    model.compile(optimizer=optimizer, loss=loss) #사용자 지정 파라미터(optimizer, loss)\n",
    "    resulit = model.fit(X_train, X_train, batch_size = batch_size, epochs=epochs, validation_data=(X_test, X_test)) #사용자 지정 파라미터(epochs)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_extraction_twentyeight(X):\n",
    "    X = normalization_tool(X) #데이터 정규화\n",
    "    \n",
    "    compressed_layer = 5\n",
    "    get_3rd_layer_output = K.function([model.layers[0].input],[model.layers[compressed_layer].output])\n",
    "    compressed = get_3rd_layer_output([X])[0]\n",
    "    \n",
    "    #일렬로 늘리기\n",
    "    compressed = compressed.reshape(compressed.shape[0], compressed.shape[1]*compressed.shape[2]*compressed.shape[3])\n",
    "    \n",
    "    return compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_extraction_ninetysix(X):\n",
    "    X = normalization_tool(X) #데이터 정규화\n",
    "    \n",
    "    compressed_layer = 8\n",
    "    get_3rd_layer_output = K.function([model.layers[0].input],[model.layers[compressed_layer].output])\n",
    "    compressed = get_3rd_layer_output([X])[0]\n",
    "    \n",
    "    #일렬로 늘리기\n",
    "    compressed = compressed.reshape(compressed.shape[0], compressed.shape[1]*compressed.shape[2]*compressed.shape[3])\n",
    "    \n",
    "    return compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
